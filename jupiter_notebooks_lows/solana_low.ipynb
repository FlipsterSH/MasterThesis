{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code represents a trading strategy for 1 hour trading intervals\n",
    "# The predictor is the low price of the Solana cryptocurrency and the minimum threshold is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# IMPORTS AND SETUP ##############################\n",
    "\n",
    "\n",
    "from binance import Client\n",
    "import pandas as pd\n",
    "from supporting_functionsM2 import *\n",
    "from API_KEYS2 import get_keys\n",
    "\n",
    "# Setting up binance client\n",
    "KEY, SECRET = get_keys()\n",
    "client = Client(KEY, SECRET)\n",
    "\n",
    "# Defining setup variables for creating dataset\n",
    "# start = \"1513724400\" # 20.12.2017\n",
    "start = \"1483225200\" # 01.01.2017\n",
    "periods = 101 # approx 8 years\n",
    "TICKER = \"SOLUSDT\"\n",
    "options = [\"high\", \"low\", \"close\", \"volume\"] # BASE OPTIONS\n",
    "EPOCHS=5\n",
    "THRESHOLD=-0.5 # Threshold value for lableling, ie. BTCUSDT:close = 0.5 > 0.0 => label = 1, if BTCUSDT:close = -0.5 < 0.0 => 0\n",
    "PREDICTOR=f\"{TICKER}:low\"\n",
    "TIME = f\"{TICKER}:time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-11 06:00:00</td>\n",
       "      <td>2.85000000</td>\n",
       "      <td>3.47000000</td>\n",
       "      <td>2.85000000</td>\n",
       "      <td>2.95150000</td>\n",
       "      <td>20032.26000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-11 07:00:00</td>\n",
       "      <td>2.95150000</td>\n",
       "      <td>3.13550000</td>\n",
       "      <td>2.88000000</td>\n",
       "      <td>2.92240000</td>\n",
       "      <td>42069.37000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-11 08:00:00</td>\n",
       "      <td>2.96260000</td>\n",
       "      <td>3.00000000</td>\n",
       "      <td>2.91440000</td>\n",
       "      <td>2.96000000</td>\n",
       "      <td>24280.76000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-11 09:00:00</td>\n",
       "      <td>2.96000000</td>\n",
       "      <td>2.97360000</td>\n",
       "      <td>2.85000000</td>\n",
       "      <td>2.85430000</td>\n",
       "      <td>26371.23000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-11 10:00:00</td>\n",
       "      <td>2.85660000</td>\n",
       "      <td>2.93290000</td>\n",
       "      <td>2.84330000</td>\n",
       "      <td>2.89760000</td>\n",
       "      <td>26685.94000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41064</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>133.92000000</td>\n",
       "      <td>134.20000000</td>\n",
       "      <td>133.55000000</td>\n",
       "      <td>134.00000000</td>\n",
       "      <td>53605.20200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41065</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>134.01000000</td>\n",
       "      <td>134.47000000</td>\n",
       "      <td>133.73000000</td>\n",
       "      <td>134.21000000</td>\n",
       "      <td>52051.10600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41066</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>134.21000000</td>\n",
       "      <td>134.32000000</td>\n",
       "      <td>133.48000000</td>\n",
       "      <td>134.09000000</td>\n",
       "      <td>37999.64400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41067</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>134.10000000</td>\n",
       "      <td>134.40000000</td>\n",
       "      <td>133.78000000</td>\n",
       "      <td>134.27000000</td>\n",
       "      <td>37406.54600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41068</th>\n",
       "      <td>2025-04-18 22:00:00</td>\n",
       "      <td>134.28000000</td>\n",
       "      <td>134.36000000</td>\n",
       "      <td>133.92000000</td>\n",
       "      <td>133.92000000</td>\n",
       "      <td>36707.60100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41069 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time          open          high           low  \\\n",
       "0      2020-08-11 06:00:00    2.85000000    3.47000000    2.85000000   \n",
       "1      2020-08-11 07:00:00    2.95150000    3.13550000    2.88000000   \n",
       "2      2020-08-11 08:00:00    2.96260000    3.00000000    2.91440000   \n",
       "3      2020-08-11 09:00:00    2.96000000    2.97360000    2.85000000   \n",
       "4      2020-08-11 10:00:00    2.85660000    2.93290000    2.84330000   \n",
       "...                    ...           ...           ...           ...   \n",
       "41064  2025-04-18 18:00:00  133.92000000  134.20000000  133.55000000   \n",
       "41065  2025-04-18 19:00:00  134.01000000  134.47000000  133.73000000   \n",
       "41066  2025-04-18 20:00:00  134.21000000  134.32000000  133.48000000   \n",
       "41067  2025-04-18 21:00:00  134.10000000  134.40000000  133.78000000   \n",
       "41068  2025-04-18 22:00:00  134.28000000  134.36000000  133.92000000   \n",
       "\n",
       "              close          volume  \n",
       "0        2.95150000  20032.26000000  \n",
       "1        2.92240000  42069.37000000  \n",
       "2        2.96000000  24280.76000000  \n",
       "3        2.85430000  26371.23000000  \n",
       "4        2.89760000  26685.94000000  \n",
       "...             ...             ...  \n",
       "41064  134.00000000  53605.20200000  \n",
       "41065  134.21000000  52051.10600000  \n",
       "41066  134.09000000  37999.64400000  \n",
       "41067  134.27000000  37406.54600000  \n",
       "41068  133.92000000  36707.60100000  \n",
       "\n",
       "[41069 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# DOWNLOADING RAW DATA ##########################################\n",
    "\n",
    "periods = periods\n",
    "LIMIT = 720 # 720h = 30 days\n",
    "start1 = start\n",
    "end1 = next_30_days_unix_timestamp(start1)\n",
    "\n",
    "############################################ DOWNLOADING DATA ###################################################################### \n",
    "data = pd.DataFrame(columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "# downloading the first set of candlestick lines\n",
    "klines = client.get_historical_klines(TICKER, client.KLINE_INTERVAL_1HOUR, limit=LIMIT, start_str=unix_to_datetime_string(start1, in_milliseconds=False), end_str=unix_to_datetime_string(end1, in_milliseconds=False))\n",
    "    # print(klines)\n",
    "\n",
    "# Converting data from list to pandas dataframe\n",
    "new_data = pd.DataFrame(data=[row[0:6] for row in klines], columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "data = pd.concat([data, new_data], ignore_index=True)\n",
    "\n",
    "for i in range(periods - 1):\n",
    "    # Moving the start and end interval to next day\n",
    "    start1 = next_30_days_unix_timestamp(start1)\n",
    "    end1 = next_30_days_unix_timestamp(start1) \n",
    "\n",
    "    # downloading candlestick lines\n",
    "    klines = client.get_historical_klines(TICKER, client.KLINE_INTERVAL_1HOUR, limit=LIMIT, start_str=unix_to_datetime_string(start1, in_milliseconds=False), end_str=unix_to_datetime_string(end1, in_milliseconds=False))\n",
    "    # print(klines)\n",
    "\n",
    "    # Converting data from list to pandas dataframe\n",
    "    new_data = pd.DataFrame(data=[row[0:6] for row in klines], columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # concatinating the new data with the existing data\n",
    "    data = pd.concat([data, new_data], ignore_index=True)\n",
    "\n",
    "# converting all time values from unix to readable string, not important, just for visual purposes and fact checking\n",
    "data[\"time\"] = data[\"time\"].apply(unix_to_datetime_string) #converting time from \n",
    "\n",
    "raw_data = data\n",
    "display(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENT RETURN EVALUATION SET: 21.293361108595228\n"
     ]
    }
   ],
   "source": [
    "raw_close = raw_data['close'].to_list()\n",
    "print(f\"PERCENT RETURN EVALUATION SET: {percent_difference(float(raw_close[-10000]), float(raw_close[-1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOLUSDT:time</th>\n",
       "      <th>SOLUSDT:high</th>\n",
       "      <th>SOLUSDT:low</th>\n",
       "      <th>SOLUSDT:close</th>\n",
       "      <th>SOLUSDT:volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-11 07:00:00</td>\n",
       "      <td>6.234118</td>\n",
       "      <td>-2.422497</td>\n",
       "      <td>-0.985939</td>\n",
       "      <td>110.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-11 08:00:00</td>\n",
       "      <td>1.262405</td>\n",
       "      <td>-1.626949</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-42.283994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-11 09:00:00</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>-3.716216</td>\n",
       "      <td>-3.570946</td>\n",
       "      <td>8.609574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-11 10:00:00</td>\n",
       "      <td>2.671007</td>\n",
       "      <td>-0.465588</td>\n",
       "      <td>1.435273</td>\n",
       "      <td>1.193384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-11 11:00:00</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>-0.521137</td>\n",
       "      <td>4.559948</td>\n",
       "      <td>-53.254298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41063</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>-0.276284</td>\n",
       "      <td>0.059737</td>\n",
       "      <td>-5.914184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41064</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>-0.208940</td>\n",
       "      <td>0.149243</td>\n",
       "      <td>-2.899151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41065</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>0.081961</td>\n",
       "      <td>-0.543924</td>\n",
       "      <td>-0.089412</td>\n",
       "      <td>-26.995511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41066</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>-0.238628</td>\n",
       "      <td>0.126771</td>\n",
       "      <td>-1.560799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41067</th>\n",
       "      <td>2025-04-18 22:00:00</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>-0.268097</td>\n",
       "      <td>-0.268097</td>\n",
       "      <td>-1.868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41068 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SOLUSDT:time  SOLUSDT:high  SOLUSDT:low  SOLUSDT:close  \\\n",
       "0      2020-08-11 07:00:00      6.234118    -2.422497      -0.985939   \n",
       "1      2020-08-11 08:00:00      1.262405    -1.626949      -0.087761   \n",
       "2      2020-08-11 09:00:00      0.459459    -3.716216      -3.570946   \n",
       "3      2020-08-11 10:00:00      2.671007    -0.465588       1.435273   \n",
       "4      2020-08-11 11:00:00      6.284500    -0.521137       4.559948   \n",
       "...                    ...           ...          ...            ...   \n",
       "41063  2025-04-18 18:00:00      0.209080    -0.276284       0.059737   \n",
       "41064  2025-04-18 19:00:00      0.343258    -0.208940       0.149243   \n",
       "41065  2025-04-18 20:00:00      0.081961    -0.543924      -0.089412   \n",
       "41066  2025-04-18 21:00:00      0.223714    -0.238628       0.126771   \n",
       "41067  2025-04-18 22:00:00      0.059577    -0.268097      -0.268097   \n",
       "\n",
       "       SOLUSDT:volume  \n",
       "0          110.008107  \n",
       "1          -42.283994  \n",
       "2            8.609574  \n",
       "3            1.193384  \n",
       "4          -53.254298  \n",
       "...               ...  \n",
       "41063       -5.914184  \n",
       "41064       -2.899151  \n",
       "41065      -26.995511  \n",
       "41066       -1.560799  \n",
       "41067       -1.868510  \n",
       "\n",
       "[41068 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################## PREPROCESSING DATA ####################################################################\n",
    "\n",
    "# New dataobject for storing processed data\n",
    "# processed_data = {f\"{TICKER}:time\": [], f\"{TICKER}:open\": [], f\"{TICKER}:high\": [], f\"{TICKER}:low\": [], f\"{TICKER}:close\": [], f\"{TICKER}:volume\": []}\n",
    "processed_data = {f\"{TICKER}:time\": [], f\"{TICKER}:high\": [], f\"{TICKER}:low\": [], f\"{TICKER}:close\": [], f\"{TICKER}:volume\": []}\n",
    "\n",
    "for i, o in enumerate(raw_data[\"open\"]): #o == open, the open price value of the candle stick\n",
    "    if i == 0: #Skipping the first hour to calculate the percent diff using this hour\n",
    "        continue\n",
    "\n",
    "    if o == 0:\n",
    "        continue\n",
    "\n",
    "    processed_data[f\"{TICKER}:time\"].append(raw_data[\"time\"][i]) #time is the same\n",
    "    # processed_data[f\"{TICKER}:open\"].append(percent_difference(float(data[\"open\"][i-1]), float(o))) # percent difference between the opening price of the prior candlestick vs. open of current candle\n",
    "    processed_data[f\"{TICKER}:high\"].append(percent_difference(float(o), float(raw_data[\"high\"][i]))) # percent diff between open and high\n",
    "    processed_data[f\"{TICKER}:low\"].append(percent_difference(float(o), float(raw_data[\"low\"][i]))) # percent diff between open and low\n",
    "    processed_data[f\"{TICKER}:close\"].append(percent_difference(float(o), float(raw_data[\"close\"][i]))) # percent diff between open and close\n",
    "    processed_data[f\"{TICKER}:volume\"].append(percent_difference(float(raw_data[\"volume\"][i-1]), float(raw_data[\"volume\"][i]))) # percent difference between the colume of the prior candlestick vs. open of current candle\n",
    "\n",
    "\n",
    "# processed_data = pd.DataFrame(data=processed_data, columns=[f\"{TICKER}:time\", f\"{TICKER}:open\", f\"{TICKER}:high\", f\"{TICKER}:low\", f\"{TICKER}:close\", f\"{TICKER}:volume\"])\n",
    "processed_data = pd.DataFrame(data=processed_data, columns=[f\"{TICKER}:time\", f\"{TICKER}:high\", f\"{TICKER}:low\", f\"{TICKER}:close\", f\"{TICKER}:volume\"])\n",
    "display(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DATAPOINTS: 31068\n",
      "MEAN LOW: -1.0032620985435312\n",
      "MEDIAN LOW: -0.6406774980982002\n",
      "MIN LOW IN DATASET: -39.69460437384794\n",
      "OCCURRENCES UNDER -0.5: 18330 - PERCENT OF DATASET: 0.59%\n",
      "OCCURRENCES UNDER -0.6: 16313 - PERCENT OF DATASET: 0.53%\n",
      "OCCURRENCES UNDER -0.7: 14529 - PERCENT OF DATASET: 0.47%\n",
      "OCCURRENCES UNDER -0.8: 12997 - PERCENT OF DATASET: 0.42%\n",
      "OCCURRENCES UNDER -0.9: 11628 - PERCENT OF DATASET: 0.37%\n",
      "OCCURRENCES UNDER -1: 10461 - PERCENT OF DATASET: 0.34%\n",
      "----------------------------------------------------------------------\n",
      "EVALUATION DATASET\n",
      "TOTAL DATAPOINTS: 10000\n",
      "MEAN LOW: -0.7211085975118239\n",
      "MEDIAN LOW: -0.47977324946326655\n",
      "MIN LOW IN DATASET: -21.424186617556774\n",
      "OCCURRENCES UNDER -0.5: 4856 - PERCENT OF DATASET: 0.49%\n",
      "OCCURRENCES UNDER -0.6: 4119 - PERCENT OF DATASET: 0.41%\n",
      "OCCURRENCES UNDER -0.7: 3496 - PERCENT OF DATASET: 0.35%\n",
      "OCCURRENCES UNDER -0.8: 2990 - PERCENT OF DATASET: 0.3%\n",
      "OCCURRENCES UNDER -0.9: 2560 - PERCENT OF DATASET: 0.26%\n",
      "OCCURRENCES UNDER -1: 2217 - PERCENT OF DATASET: 0.22%\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "############################# STATISTICAL ANALYSIS OF PROCESSED DATA #######################################\n",
    "import statistics as st\n",
    "\n",
    "low_data_processed = processed_data[f\"{TICKER}:low\"].to_list()\n",
    "low_data_processed = low_data_processed[:-10000]\n",
    "print(f\"TOTAL DATAPOINTS: {len(low_data_processed)}\")\n",
    "print(f\"MEAN LOW: {st.mean(low_data_processed)}\")\n",
    "print(f\"MEDIAN LOW: {st.median(low_data_processed)}\")\n",
    "\n",
    "print(f\"MIN LOW IN DATASET: {min(low_data_processed)}\")\n",
    "print(f\"OCCURRENCES UNDER -0.5: {sum(x < -0.5 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.5 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.6: {sum(x < -0.6 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.6 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.7: {sum(x < -0.7 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.7 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.8: {sum(x < -0.8 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.8 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.9: {sum(x < -0.9 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.9 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -1: {sum(x < -1 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -1 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "print(\"EVALUATION DATASET\")\n",
    "low_data_processed = low_data_processed[-10000:]\n",
    "print(f\"TOTAL DATAPOINTS: {len(low_data_processed)}\")\n",
    "print(f\"MEAN LOW: {st.mean(low_data_processed)}\")\n",
    "print(f\"MEDIAN LOW: {st.median(low_data_processed)}\")\n",
    "\n",
    "print(f\"MIN LOW IN DATASET: {min(low_data_processed)}\")\n",
    "print(f\"OCCURRENCES UNDER -0.5: {sum(x < -0.5 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.5 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.6: {sum(x < -0.6 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.6 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.7: {sum(x < -0.7 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.7 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.8: {sum(x < -0.8 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.8 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -0.9: {sum(x < -0.9 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -0.9 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(f\"OCCURRENCES UNDER -1: {sum(x < -1 for x in low_data_processed)} - PERCENT OF DATASET: {round(sum(x < -1 for x in low_data_processed) / len(low_data_processed), 2)}%\")\n",
    "print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>SOLUSDT:high0</th>\n",
       "      <th>SOLUSDT:low0</th>\n",
       "      <th>SOLUSDT:close0</th>\n",
       "      <th>SOLUSDT:volume0</th>\n",
       "      <th>SOLUSDT:high1</th>\n",
       "      <th>SOLUSDT:low1</th>\n",
       "      <th>SOLUSDT:close1</th>\n",
       "      <th>SOLUSDT:volume1</th>\n",
       "      <th>SOLUSDT:high2</th>\n",
       "      <th>...</th>\n",
       "      <th>SOLUSDT:volume2</th>\n",
       "      <th>SOLUSDT:high3</th>\n",
       "      <th>SOLUSDT:low3</th>\n",
       "      <th>SOLUSDT:close3</th>\n",
       "      <th>SOLUSDT:volume3</th>\n",
       "      <th>SOLUSDT:high4</th>\n",
       "      <th>SOLUSDT:low4</th>\n",
       "      <th>SOLUSDT:close4</th>\n",
       "      <th>SOLUSDT:volume4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-11 11:00:00</td>\n",
       "      <td>6.234118</td>\n",
       "      <td>-2.422497</td>\n",
       "      <td>-0.985939</td>\n",
       "      <td>110.008107</td>\n",
       "      <td>1.262405</td>\n",
       "      <td>-1.626949</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-42.283994</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>...</td>\n",
       "      <td>8.609574</td>\n",
       "      <td>2.671007</td>\n",
       "      <td>-0.465588</td>\n",
       "      <td>1.435273</td>\n",
       "      <td>1.193384</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>-0.521137</td>\n",
       "      <td>4.559948</td>\n",
       "      <td>-53.254298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-11 12:00:00</td>\n",
       "      <td>1.262405</td>\n",
       "      <td>-1.626949</td>\n",
       "      <td>-0.087761</td>\n",
       "      <td>-42.283994</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>-3.716216</td>\n",
       "      <td>-3.570946</td>\n",
       "      <td>8.609574</td>\n",
       "      <td>2.671007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193384</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>-0.521137</td>\n",
       "      <td>4.559948</td>\n",
       "      <td>-53.254298</td>\n",
       "      <td>9.158278</td>\n",
       "      <td>-0.029511</td>\n",
       "      <td>2.013313</td>\n",
       "      <td>996.471931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-11 13:00:00</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>-3.716216</td>\n",
       "      <td>-3.570946</td>\n",
       "      <td>8.609574</td>\n",
       "      <td>2.671007</td>\n",
       "      <td>-0.465588</td>\n",
       "      <td>1.435273</td>\n",
       "      <td>1.193384</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.254298</td>\n",
       "      <td>9.158278</td>\n",
       "      <td>-0.029511</td>\n",
       "      <td>2.013313</td>\n",
       "      <td>996.471931</td>\n",
       "      <td>5.329476</td>\n",
       "      <td>-7.987785</td>\n",
       "      <td>5.329476</td>\n",
       "      <td>70.368275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-11 14:00:00</td>\n",
       "      <td>2.671007</td>\n",
       "      <td>-0.465588</td>\n",
       "      <td>1.435273</td>\n",
       "      <td>1.193384</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>-0.521137</td>\n",
       "      <td>4.559948</td>\n",
       "      <td>-53.254298</td>\n",
       "      <td>9.158278</td>\n",
       "      <td>...</td>\n",
       "      <td>996.471931</td>\n",
       "      <td>5.329476</td>\n",
       "      <td>-7.987785</td>\n",
       "      <td>5.329476</td>\n",
       "      <td>70.368275</td>\n",
       "      <td>7.384024</td>\n",
       "      <td>-6.231128</td>\n",
       "      <td>-0.878397</td>\n",
       "      <td>55.447469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-11 15:00:00</td>\n",
       "      <td>6.284500</td>\n",
       "      <td>-0.521137</td>\n",
       "      <td>4.559948</td>\n",
       "      <td>-53.254298</td>\n",
       "      <td>9.158278</td>\n",
       "      <td>-0.029511</td>\n",
       "      <td>2.013313</td>\n",
       "      <td>996.471931</td>\n",
       "      <td>5.329476</td>\n",
       "      <td>...</td>\n",
       "      <td>70.368275</td>\n",
       "      <td>7.384024</td>\n",
       "      <td>-6.231128</td>\n",
       "      <td>-0.878397</td>\n",
       "      <td>55.447469</td>\n",
       "      <td>4.390904</td>\n",
       "      <td>-3.073941</td>\n",
       "      <td>-1.843134</td>\n",
       "      <td>-52.840987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41058</th>\n",
       "      <td>2025-04-18 17:00:00</td>\n",
       "      <td>0.088942</td>\n",
       "      <td>-0.622591</td>\n",
       "      <td>-0.259413</td>\n",
       "      <td>0.299183</td>\n",
       "      <td>0.237812</td>\n",
       "      <td>-1.144471</td>\n",
       "      <td>-0.921522</td>\n",
       "      <td>-4.557556</td>\n",
       "      <td>0.142504</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.954414</td>\n",
       "      <td>0.458957</td>\n",
       "      <td>-0.165526</td>\n",
       "      <td>0.383718</td>\n",
       "      <td>-66.448224</td>\n",
       "      <td>0.712091</td>\n",
       "      <td>-0.262349</td>\n",
       "      <td>0.382280</td>\n",
       "      <td>-3.606008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41059</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>0.237812</td>\n",
       "      <td>-1.144471</td>\n",
       "      <td>-0.921522</td>\n",
       "      <td>-4.557556</td>\n",
       "      <td>0.142504</td>\n",
       "      <td>-0.645016</td>\n",
       "      <td>-0.315008</td>\n",
       "      <td>-16.954414</td>\n",
       "      <td>0.458957</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.448224</td>\n",
       "      <td>0.712091</td>\n",
       "      <td>-0.262349</td>\n",
       "      <td>0.382280</td>\n",
       "      <td>-3.606008</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>-0.276284</td>\n",
       "      <td>0.059737</td>\n",
       "      <td>-5.914184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41060</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>0.142504</td>\n",
       "      <td>-0.645016</td>\n",
       "      <td>-0.315008</td>\n",
       "      <td>-16.954414</td>\n",
       "      <td>0.458957</td>\n",
       "      <td>-0.165526</td>\n",
       "      <td>0.383718</td>\n",
       "      <td>-66.448224</td>\n",
       "      <td>0.712091</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.606008</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>-0.276284</td>\n",
       "      <td>0.059737</td>\n",
       "      <td>-5.914184</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>-0.208940</td>\n",
       "      <td>0.149243</td>\n",
       "      <td>-2.899151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41061</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>0.458957</td>\n",
       "      <td>-0.165526</td>\n",
       "      <td>0.383718</td>\n",
       "      <td>-66.448224</td>\n",
       "      <td>0.712091</td>\n",
       "      <td>-0.262349</td>\n",
       "      <td>0.382280</td>\n",
       "      <td>-3.606008</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.914184</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>-0.208940</td>\n",
       "      <td>0.149243</td>\n",
       "      <td>-2.899151</td>\n",
       "      <td>0.081961</td>\n",
       "      <td>-0.543924</td>\n",
       "      <td>-0.089412</td>\n",
       "      <td>-26.995511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41062</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>0.712091</td>\n",
       "      <td>-0.262349</td>\n",
       "      <td>0.382280</td>\n",
       "      <td>-3.606008</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>-0.276284</td>\n",
       "      <td>0.059737</td>\n",
       "      <td>-5.914184</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.899151</td>\n",
       "      <td>0.081961</td>\n",
       "      <td>-0.543924</td>\n",
       "      <td>-0.089412</td>\n",
       "      <td>-26.995511</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>-0.238628</td>\n",
       "      <td>0.126771</td>\n",
       "      <td>-1.560799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41063 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time  SOLUSDT:high0  SOLUSDT:low0  SOLUSDT:close0  \\\n",
       "0      2020-08-11 11:00:00       6.234118     -2.422497       -0.985939   \n",
       "1      2020-08-11 12:00:00       1.262405     -1.626949       -0.087761   \n",
       "2      2020-08-11 13:00:00       0.459459     -3.716216       -3.570946   \n",
       "3      2020-08-11 14:00:00       2.671007     -0.465588        1.435273   \n",
       "4      2020-08-11 15:00:00       6.284500     -0.521137        4.559948   \n",
       "...                    ...            ...           ...             ...   \n",
       "41058  2025-04-18 17:00:00       0.088942     -0.622591       -0.259413   \n",
       "41059  2025-04-18 18:00:00       0.237812     -1.144471       -0.921522   \n",
       "41060  2025-04-18 19:00:00       0.142504     -0.645016       -0.315008   \n",
       "41061  2025-04-18 20:00:00       0.458957     -0.165526        0.383718   \n",
       "41062  2025-04-18 21:00:00       0.712091     -0.262349        0.382280   \n",
       "\n",
       "       SOLUSDT:volume0  SOLUSDT:high1  SOLUSDT:low1  SOLUSDT:close1  \\\n",
       "0           110.008107       1.262405     -1.626949       -0.087761   \n",
       "1           -42.283994       0.459459     -3.716216       -3.570946   \n",
       "2             8.609574       2.671007     -0.465588        1.435273   \n",
       "3             1.193384       6.284500     -0.521137        4.559948   \n",
       "4           -53.254298       9.158278     -0.029511        2.013313   \n",
       "...                ...            ...           ...             ...   \n",
       "41058         0.299183       0.237812     -1.144471       -0.921522   \n",
       "41059        -4.557556       0.142504     -0.645016       -0.315008   \n",
       "41060       -16.954414       0.458957     -0.165526        0.383718   \n",
       "41061       -66.448224       0.712091     -0.262349        0.382280   \n",
       "41062        -3.606008       0.209080     -0.276284        0.059737   \n",
       "\n",
       "       SOLUSDT:volume1  SOLUSDT:high2  ...  SOLUSDT:volume2  SOLUSDT:high3  \\\n",
       "0           -42.283994       0.459459  ...         8.609574       2.671007   \n",
       "1             8.609574       2.671007  ...         1.193384       6.284500   \n",
       "2             1.193384       6.284500  ...       -53.254298       9.158278   \n",
       "3           -53.254298       9.158278  ...       996.471931       5.329476   \n",
       "4           996.471931       5.329476  ...        70.368275       7.384024   \n",
       "...                ...            ...  ...              ...            ...   \n",
       "41058        -4.557556       0.142504  ...       -16.954414       0.458957   \n",
       "41059       -16.954414       0.458957  ...       -66.448224       0.712091   \n",
       "41060       -66.448224       0.712091  ...        -3.606008       0.209080   \n",
       "41061        -3.606008       0.209080  ...        -5.914184       0.343258   \n",
       "41062        -5.914184       0.343258  ...        -2.899151       0.081961   \n",
       "\n",
       "       SOLUSDT:low3  SOLUSDT:close3  SOLUSDT:volume3  SOLUSDT:high4  \\\n",
       "0         -0.465588        1.435273         1.193384       6.284500   \n",
       "1         -0.521137        4.559948       -53.254298       9.158278   \n",
       "2         -0.029511        2.013313       996.471931       5.329476   \n",
       "3         -7.987785        5.329476        70.368275       7.384024   \n",
       "4         -6.231128       -0.878397        55.447469       4.390904   \n",
       "...             ...             ...              ...            ...   \n",
       "41058     -0.165526        0.383718       -66.448224       0.712091   \n",
       "41059     -0.262349        0.382280        -3.606008       0.209080   \n",
       "41060     -0.276284        0.059737        -5.914184       0.343258   \n",
       "41061     -0.208940        0.149243        -2.899151       0.081961   \n",
       "41062     -0.543924       -0.089412       -26.995511       0.223714   \n",
       "\n",
       "       SOLUSDT:low4  SOLUSDT:close4  SOLUSDT:volume4  Label  \n",
       "0         -0.521137        4.559948       -53.254298      0  \n",
       "1         -0.029511        2.013313       996.471931      1  \n",
       "2         -7.987785        5.329476        70.368275      1  \n",
       "3         -6.231128       -0.878397        55.447469      1  \n",
       "4         -3.073941       -1.843134       -52.840987      1  \n",
       "...             ...             ...              ...    ...  \n",
       "41058     -0.262349        0.382280        -3.606008      0  \n",
       "41059     -0.276284        0.059737        -5.914184      0  \n",
       "41060     -0.208940        0.149243        -2.899151      1  \n",
       "41061     -0.543924       -0.089412       -26.995511      0  \n",
       "41062     -0.238628        0.126771        -1.560799      0  \n",
       "\n",
       "[41063 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### LABELING THE DATA ##################################\n",
    "\n",
    "\n",
    "# column_labels = [\"BTCUSDT:time\"] # name of the columns for the return dataframe\n",
    "column_labels = [\"time\"] # name of the columns for the return dataframe\n",
    "\n",
    "# filling up the list with labels for the columns\n",
    "for roundd in range(EPOCHS):\n",
    "    for option in options:\n",
    "        column_labels.append(f\"{TICKER}:{option}{roundd}\")\n",
    "\n",
    "column_labels.append(\"Label\")\n",
    "\n",
    "\n",
    "# filling up list of data, row by row in the dataset\n",
    "labelled_data_rows = [] # this list stores all the rows filled with all the data\n",
    "for i in range(len(processed_data[TIME]) - EPOCHS): #looping from the third element to the third last element, with stepsize 1, if epoch=3\n",
    "    data_row = []\n",
    "\n",
    "    data_row.append(processed_data[TIME][i + EPOCHS - 1])\n",
    "\n",
    "    for t in range(EPOCHS):\n",
    "        for option in options:\n",
    "            data_row.append(processed_data[f\"{TICKER}:{option}\"][i + t])\n",
    "\n",
    "    if processed_data[PREDICTOR][i + EPOCHS] < THRESHOLD: # here we use the threshold\n",
    "        data_row.append(1)\n",
    "    else:\n",
    "        data_row.append(0)\n",
    "\n",
    "    labelled_data_rows.append(data_row)\n",
    "\n",
    "\n",
    "labelled_data_frame = pd.DataFrame(labelled_data_rows, columns=column_labels)\n",
    "display(labelled_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This code block divides the dataset into a training dataset and trains a new model using the **AutoGluon Tabular** predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\47981\\Desktop\\MasterThesis\\Repo\\MasterThesis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250603_112218\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       3.12 GB / 15.92 GB (19.6%)\n",
      "Disk Space Avail:   109.62 GB / 475.69 GB (23.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20250603_112218\"\n",
      "Train Data Rows:    31063\n",
      "Train Data Columns: 20\n",
      "Label Column:       Label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3176.70 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.74 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['SOLUSDT:high0', 'SOLUSDT:low0', 'SOLUSDT:close0', 'SOLUSDT:volume0', 'SOLUSDT:high1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['SOLUSDT:high0', 'SOLUSDT:low0', 'SOLUSDT:close0', 'SOLUSDT:volume0', 'SOLUSDT:high1', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.74 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08048160190580433, Train Rows: 28563, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5352\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5324\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6628\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6596\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6492\t = Validation score   (accuracy)\n",
      "\t5.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.662\t = Validation score   (accuracy)\n",
      "\t8.8s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6596\t = Validation score   (accuracy)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6536\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.654\t = Validation score   (accuracy)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.6588\t = Validation score   (accuracy)\n",
      "\t35.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.662\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n"
     ]
    }
   ],
   "source": [
    "################################ TRAINING NEW MODEL #######################################\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# defining training size and colums to use for training within the labelled dataset\n",
    "VALIDATION_SIZE = 10000\n",
    "columns_to_use = [f\"{TICKER}:high0\", f\"{TICKER}:low0\", f\"{TICKER}:close0\", f\"{TICKER}:volume0\", f\"{TICKER}:high1\", f\"{TICKER}:low1\", f\"{TICKER}:close1\", f\"{TICKER}:volume1\", f\"{TICKER}:high2\", f\"{TICKER}:low2\", f\"{TICKER}:close2\", f\"{TICKER}:volume2\", f\"{TICKER}:high3\", f\"{TICKER}:low3\", f\"{TICKER}:close3\", f\"{TICKER}:volume3\", f\"{TICKER}:high4\", f\"{TICKER}:low4\", f\"{TICKER}:close4\", f\"{TICKER}:volume4\", \"Label\"]\n",
    "LABEL = \"Label\"\n",
    "\n",
    "# defining training data\n",
    "training_dataframe = labelled_data_frame.iloc[:-VALIDATION_SIZE].copy()\n",
    "train_data_frame2 = training_dataframe[columns_to_use]\n",
    "train_tabular_dataset = TabularDataset(train_data_frame2)\n",
    "\n",
    "# # Training model -> TabularPredictor\n",
    "# predictor = TabularPredictor(label=label, eval_metric=\"balanced_accuracy\", positive_class=1).fit(train_tabular_dataset, num_bag_folds=5, num_bag_sets=5, num_stack_levels=3)\n",
    "# predictor = TabularPredictor(label=label, eval_metric=\"accuracy\").fit(train_tabular_dataset, presets=\"high_quality\")\n",
    "predictor = TabularPredictor(label=LABEL).fit(train_tabular_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This code block divides the dataset into a validation dataset and evaluates the model using the **AutoGluons** inbuilt evaluation library. In addition the model is backtested using the validation set to measure its performance and calulate its \"expected return\" over the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### MODEL EVALUATION ################################\n",
    "\n",
    "# Defining the testing set using the training size and columns to use\n",
    "testing_dataframe = labelled_data_frame.tail(VALIDATION_SIZE).copy()\n",
    "#display(testing_dataframe)\n",
    "test_data_frame2 = testing_dataframe[columns_to_use]\n",
    "test_tabular_dataset = TabularDataset(test_data_frame2)\n",
    "\n",
    "######## Making predictions\n",
    "y_pred = predictor.predict(test_tabular_dataset.drop(columns=[LABEL]))\n",
    "display(y_pred)\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "eval_report = predictor.evaluate(test_tabular_dataset, detailed_report=True)\n",
    "display(eval_report)\n",
    "\n",
    "feature_importance = predictor.feature_importance(test_tabular_dataset)\n",
    "display(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "METRIC_RE = re.compile(r\":([a-zA-Z]+?)(\\d+)$\")   # capture metric & hour suffix\n",
    "\n",
    "\n",
    "def analyze_feature_importance(feature_names, importances):\n",
    "    \"\"\"\n",
    "    Print a short report on a modelâ€™s feature-importance vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_names : list[str]\n",
    "        All feature names, e.g. [\"SOLUSDT:high4\", \"SOLUSDT:low2\", ...]\n",
    "    importances : list[float]\n",
    "        Matching importance values, same length/order as `feature_names`\n",
    "    \"\"\"\n",
    "    if len(feature_names) != len(importances):\n",
    "        raise ValueError(\"feature_names and importances must be the same length!\")\n",
    "\n",
    "    # â”€â”€ Build a DataFrame â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df = pd.DataFrame(\n",
    "        {\"feature\": feature_names, \"importance\": importances}\n",
    "    ).assign(\n",
    "        metric=lambda d: d[\"feature\"].str.extract(METRIC_RE)[0].str.lower(),\n",
    "        hour=lambda d: pd.to_numeric(\n",
    "            d[\"feature\"].str.extract(METRIC_RE)[1], errors=\"coerce\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Drop rows we could not parse\n",
    "    df = df.dropna(subset=[\"metric\", \"hour\"]).copy()\n",
    "    df[\"hour\"] = df[\"hour\"].astype(int)\n",
    "\n",
    "    # â”€â”€ 1. % of positive importances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    pct_pos = (df[\"importance\"] > 0).mean() * 100\n",
    "\n",
    "    # â”€â”€ 2. Rank by hour (sum of importances per lag) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    hour_scores = df.groupby(\"hour\")[\"importance\"].sum().sort_values(ascending=False)\n",
    "    hour_ranking = hour_scores.index.tolist()\n",
    "\n",
    "    # â”€â”€ 3. Rank by metric (sum of importances per metric) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    metric_scores = (\n",
    "        df.groupby(\"metric\")[\"importance\"].sum().sort_values(ascending=False)\n",
    "    )\n",
    "    metric_ranking = metric_scores.index.tolist()\n",
    "\n",
    "    # â”€â”€ Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(f\"{pct_pos:.1f}% of the {len(df)} features have **positive** importance.\\n\")\n",
    "\n",
    "    print(\"Ranking by HOUR (most â†’ least important):\")\n",
    "    for i, h in enumerate(hour_ranking, 1):\n",
    "        print(f\"  {i}. h{h:<1}   sum importance = {hour_scores[h]:.6f}\")\n",
    "\n",
    "    print(\"\\nRanking by METRIC (most â†’ least important):\")\n",
    "    for i, m in enumerate(metric_ranking, 1):\n",
    "        print(f\"  {i}. {m:<6} sum importance = {metric_scores[m]:.6f}\")\n",
    "\n",
    "    top_features = (\n",
    "        df.loc[df[\"importance\"].abs().sort_values(ascending=False).index]\n",
    "        .head(5)[[\"feature\", \"importance\"]]\n",
    "    )\n",
    "    print(\"\\nTop 5 individual features:\")\n",
    "    for feat, imp in top_features.itertuples(index=False):\n",
    "        print(f\"  {feat:<25} {imp:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analyze_feature_importance(feature_importance.index.to_list(), feature_importance['importance'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS OF PREDICTIONS AND PROBABILITIES\n",
    "\n",
    "import statistics as st\n",
    "\n",
    "# making and processing probabilities from evaluation dataset\n",
    "y_prob = predictor.predict_proba(test_tabular_dataset.drop(columns=[LABEL]))\n",
    "\n",
    "validation_probabilities = pd.DataFrame(y_prob).reset_index(drop=True) # probability for each prediction\n",
    "validation_predictions = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "validation_dataset = pd.DataFrame(test_data_frame2).reset_index(drop=True)\n",
    "display(validation_probabilities)\n",
    "display(validation_predictions)\n",
    "display(validation_dataset)\n",
    "\n",
    "print(f\"MEAN PROB 1 CLASSIFICATION: {st.mean(validation_probabilities[1].to_list())}\")\n",
    "print(f\"MAX PROB 1 CLASSIFICATION: {max(validation_probabilities[1].to_list())}\")\n",
    "print(f\"MIN PROB 1 CLASSIFICATION: {min(validation_probabilities[1].to_list())}\")\n",
    "\n",
    "count_above_07 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.7)\n",
    "print(\"COUNT OF NUMBERS > 0.7:\", count_above_07)\n",
    "\n",
    "count_above_08 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.8)\n",
    "print(\"COUNT OF NUMBERS > 0.8:\", count_above_08)\n",
    "\n",
    "count_above_09 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.9)\n",
    "print(\"COUNT OF NUMBERS > 0.9:\", count_above_09)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.7\n",
    "LEVERAGE = 1\n",
    "FEE = 0.0\n",
    "GAIN = 0.5 - FEE  # Interpreted as a percentage (e.g., 0.5% if multiplied by /100)\n",
    "\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "bad_trades = []\n",
    "all_trades = []\n",
    "\n",
    "initial_investment = 100\n",
    "current_investment = initial_investment\n",
    "investment_history = []\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        total_trades += 1\n",
    "        \n",
    "        # Check if the prediction was correct\n",
    "        if validation_predictions[\"Label\"][idx] == validation_dataset[\"Label\"][idx]:\n",
    "            correct_trades += 1\n",
    "            \n",
    "            # Record the \"gain\" in your trade list\n",
    "            all_trades.append(GAIN * LEVERAGE)\n",
    "            \n",
    "            # Update current_investment by a factor of (1 + gain%)\n",
    "            current_investment *= 1 + (GAIN / 100 * LEVERAGE)\n",
    "        \n",
    "        else:\n",
    "            # A \"bad\" (wrong) trade - since this focuses on shorting the true close is multiplied by -1\n",
    "            # Grab the next close price; watch out for index out-of-range in real code\n",
    "            true_close = (validation_dataset[f\"{TICKER}:close4\"][idx + 1] * -1) - FEE\n",
    "            \n",
    "            # Record the trade details\n",
    "            bad_trades.append(round(true_close * LEVERAGE, 3))\n",
    "            all_trades.append(true_close * LEVERAGE)\n",
    "\n",
    "            # Update current_investment by (1 + some factor of true_close?)\n",
    "            current_investment *= 1 + (true_close / 100 * LEVERAGE)\n",
    "    \n",
    "    else:\n",
    "        all_trades.append(0)\n",
    "\n",
    "    # In all cases, record the current investment amount\n",
    "    investment_history.append(current_investment)\n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "total_return = current_investment - initial_investment\n",
    "\n",
    "# --- Print results ---\n",
    "#print(f\"CORRECT: {correct_trades}\")\n",
    "#print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "print(f\"ACCURACY: {round(win_rate, 2)}%\")\n",
    "print(f\"RETURN: {round(total_return, 2)}%\")\n",
    "#print(f\"INVESTMENT VALUE: {round(current_investment, 2)}\")\n",
    "print(f\"SHARP RATIO: {calculate_sharpe_ratio(all_trades)}\")\n",
    "sharpe_ratio9999 = calculate_sharpe_ratio(validation_dataset[f\"{TICKER}:close4\"].to_list())\n",
    "print(f\"SHARP RATIO ONLY HOLDING ASSET: {sharpe_ratio9999}\")\n",
    "print(f\"MEAN RETURN BAD TRADES: {st.mean(bad_trades)}\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "# Print information about bad trades\n",
    "for trade in bad_trades:\n",
    "    print(trade)\n",
    "\n",
    "# --- Plot the investment history ---\n",
    "true_closes_list = validation_dataset[f\"{TICKER}:close4\"].to_list()\n",
    "true_close_base = 100\n",
    "true_close_base_list = []\n",
    "\n",
    "for close in true_closes_list:\n",
    "    true_close_base *= 1 + (close / 100)\n",
    "    true_close_base_list.append(true_close_base)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(investment_history, label=\"Trading Results\", color='red', linewidth=2.5)\n",
    "plt.plot(true_close_base_list, label=\"True Closes\", color='gray', linewidth=1)\n",
    "plt.xlabel(\"Back-test period (h)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Investment Value and True Closes Over Trades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ANALYSIS OF TRADING USING CLOSING PRICE ################################\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.8\n",
    "TRADING_FEE = 0.25\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "wrong_trades = 0\n",
    "\n",
    "all_trades = []\n",
    "good_trades = []\n",
    "bad_trades = []\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        true_close = validation_dataset[f\"{TICKER}:close4\"][idx + 1] - TRADING_FEE\n",
    "        \n",
    "        if true_close >= 0:\n",
    "            correct_trades += 1\n",
    "            good_trades.append(true_close)\n",
    "        else:\n",
    "            bad_trades.append(true_close)\n",
    "\n",
    "\n",
    "\n",
    "        total_trades += 1\n",
    "        all_trades.append(true_close)\n",
    "            \n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"CORRECT: {correct_trades}\")\n",
    "print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "print(f\"WIN RATE: {round(win_rate, 2)}%\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "print(f\"MEAN GOOD TRADES: {st.mean(good_trades)}\")\n",
    "print(f\"MEAN BAD TRADES: {st.mean(bad_trades)}\")\n",
    "\n",
    "investtt = 100\n",
    "investment_history2 = []\n",
    "for trade in all_trades:\n",
    "    investtt *= 1 + (trade / 100)\n",
    "    investment_history2.append(investtt)\n",
    "    # print(trade)\n",
    "\n",
    "print(f\"RETURN: {round(investtt - 100, 3)} %\")\n",
    "\n",
    "# --- Plot the investment history ---\n",
    "plt.plot(investment_history2)\n",
    "plt.xlabel(\"Trade Index\")\n",
    "plt.ylabel(\"Investment Value\")\n",
    "plt.title(\"Investment Value Over Trades\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ANALYSIS OF TRADING USING CLOSING PRICE ################################\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.8\n",
    "TRADING_FEE = 0.25\n",
    "LEVERAGE = 1\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "wrong_trades = 0\n",
    "\n",
    "all_trades = []\n",
    "good_trades = []\n",
    "bad_trades = []\n",
    "investment_value = 100\n",
    "investment_history = []\n",
    "\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        true_close = (validation_dataset[f\"{TICKER}:close4\"][idx + 1] - TRADING_FEE) * LEVERAGE\n",
    "        \n",
    "        if true_close >= 0:\n",
    "            correct_trades += 1\n",
    "            good_trades.append(true_close)\n",
    "        else:\n",
    "            bad_trades.append(true_close)\n",
    "\n",
    "\n",
    "\n",
    "        total_trades += 1\n",
    "        all_trades.append(true_close)\n",
    "\n",
    "        investment_value *= 1 + (true_close / 100)\n",
    "        investment_history.append(investment_value)\n",
    "    \n",
    "    else:\n",
    "        investment_history.append(investment_value)\n",
    "\n",
    "            \n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"CORRECT: {correct_trades}\")\n",
    "print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "print(f\"WIN RATE: {round(win_rate, 2)}%\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "print(f\"MEAN GOOD TRADES: {st.mean(good_trades)}\")\n",
    "print(f\"MEAN BAD TRADES: {st.mean(bad_trades)}\")\n",
    "print(f\"INVESTMENT VALUE {investment_value}\")\n",
    "\n",
    "# investtt = 100\n",
    "# investment_history2 = []\n",
    "# for trade in all_trades:\n",
    "#     investtt *= 1 + (trade / 100)\n",
    "#     investment_history2.append(investtt)\n",
    "#     # print(trade)\n",
    "\n",
    "# print(f\"RETURN: {round(investtt - 100, 3)} %\")\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# --- Plot the investment history ---\n",
    "\n",
    "\n",
    "plt.plot(investment_history)\n",
    "plt.xlabel(\"Trade Index\")\n",
    "plt.ylabel(\"Investment Value\")\n",
    "plt.title(\"Investment Value Over Trades\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
