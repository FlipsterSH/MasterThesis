{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code represents a trading strategy for 1 hour trading intervals\n",
    "# The predictor is the close price of the ADA cryptocurrency and the minimum threshold is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# IMPORTS AND SETUP ##############################\n",
    "\n",
    "\n",
    "from binance import Client\n",
    "import pandas as pd\n",
    "from supporting_functionsM2 import *\n",
    "from API_KEYS2 import get_keys\n",
    "\n",
    "# Setting up binance client\n",
    "KEY, SECRET = get_keys()\n",
    "client = Client(KEY, SECRET)\n",
    "\n",
    "# Defining setup variables for creating dataset\n",
    "# start = \"1513724400\" # 20.12.2017\n",
    "start = \"1483225200\" # 01.01.2017\n",
    "periods = 101 # approx 8 years\n",
    "TICKER = \"ADAUSDT\"\n",
    "options = [\"high\", \"low\", \"close\", \"volume\"] # BASE OPTIONS\n",
    "EPOCHS=5\n",
    "THRESHOLD=0.1 # Threshold value for lableling, ie. BTCUSDT:close = 0.5 > 0.0 => label = 1, if BTCUSDT:close = -0.5 < 0.0 => 0\n",
    "PREDICTOR=f\"{TICKER}:close\"\n",
    "TIME = f\"{TICKER}:time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-17 04:00:00</td>\n",
       "      <td>0.25551000</td>\n",
       "      <td>0.28800000</td>\n",
       "      <td>0.25551000</td>\n",
       "      <td>0.26664000</td>\n",
       "      <td>8143693.23000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-17 05:00:00</td>\n",
       "      <td>0.26660000</td>\n",
       "      <td>0.27798000</td>\n",
       "      <td>0.26010000</td>\n",
       "      <td>0.26200000</td>\n",
       "      <td>8317923.61000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-17 06:00:00</td>\n",
       "      <td>0.26221000</td>\n",
       "      <td>0.26396000</td>\n",
       "      <td>0.24800000</td>\n",
       "      <td>0.25664000</td>\n",
       "      <td>8420095.41000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-17 07:00:00</td>\n",
       "      <td>0.25662000</td>\n",
       "      <td>0.26300000</td>\n",
       "      <td>0.25489000</td>\n",
       "      <td>0.25698000</td>\n",
       "      <td>4686043.91000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17 08:00:00</td>\n",
       "      <td>0.25636000</td>\n",
       "      <td>0.25998000</td>\n",
       "      <td>0.25229000</td>\n",
       "      <td>0.25631000</td>\n",
       "      <td>3510038.13000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61338</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>0.62620000</td>\n",
       "      <td>0.62920000</td>\n",
       "      <td>0.62480000</td>\n",
       "      <td>0.62700000</td>\n",
       "      <td>3811821.50000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61339</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>0.62690000</td>\n",
       "      <td>0.62850000</td>\n",
       "      <td>0.62530000</td>\n",
       "      <td>0.62740000</td>\n",
       "      <td>1910694.50000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61340</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>0.62730000</td>\n",
       "      <td>0.62870000</td>\n",
       "      <td>0.62560000</td>\n",
       "      <td>0.62810000</td>\n",
       "      <td>2539948.40000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61341</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>0.62810000</td>\n",
       "      <td>0.63180000</td>\n",
       "      <td>0.62620000</td>\n",
       "      <td>0.63100000</td>\n",
       "      <td>6388871.80000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61342</th>\n",
       "      <td>2025-04-18 22:00:00</td>\n",
       "      <td>0.63110000</td>\n",
       "      <td>0.63200000</td>\n",
       "      <td>0.62730000</td>\n",
       "      <td>0.62760000</td>\n",
       "      <td>4332621.80000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61343 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time        open        high         low       close  \\\n",
       "0      2018-04-17 04:00:00  0.25551000  0.28800000  0.25551000  0.26664000   \n",
       "1      2018-04-17 05:00:00  0.26660000  0.27798000  0.26010000  0.26200000   \n",
       "2      2018-04-17 06:00:00  0.26221000  0.26396000  0.24800000  0.25664000   \n",
       "3      2018-04-17 07:00:00  0.25662000  0.26300000  0.25489000  0.25698000   \n",
       "4      2018-04-17 08:00:00  0.25636000  0.25998000  0.25229000  0.25631000   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "61338  2025-04-18 18:00:00  0.62620000  0.62920000  0.62480000  0.62700000   \n",
       "61339  2025-04-18 19:00:00  0.62690000  0.62850000  0.62530000  0.62740000   \n",
       "61340  2025-04-18 20:00:00  0.62730000  0.62870000  0.62560000  0.62810000   \n",
       "61341  2025-04-18 21:00:00  0.62810000  0.63180000  0.62620000  0.63100000   \n",
       "61342  2025-04-18 22:00:00  0.63110000  0.63200000  0.62730000  0.62760000   \n",
       "\n",
       "                 volume  \n",
       "0      8143693.23000000  \n",
       "1      8317923.61000000  \n",
       "2      8420095.41000000  \n",
       "3      4686043.91000000  \n",
       "4      3510038.13000000  \n",
       "...                 ...  \n",
       "61338  3811821.50000000  \n",
       "61339  1910694.50000000  \n",
       "61340  2539948.40000000  \n",
       "61341  6388871.80000000  \n",
       "61342  4332621.80000000  \n",
       "\n",
       "[61343 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# DOWNLOADING RAW DATA ##########################################\n",
    "\n",
    "periods = periods\n",
    "LIMIT = 720 # 720h = 30 days\n",
    "start1 = start\n",
    "end1 = next_30_days_unix_timestamp(start1)\n",
    "\n",
    "############################################ DOWNLOADING DATA ###################################################################### \n",
    "data = pd.DataFrame(columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "# downloading the first set of candlestick lines\n",
    "klines = client.get_historical_klines(TICKER, client.KLINE_INTERVAL_1HOUR, limit=LIMIT, start_str=unix_to_datetime_string(start1, in_milliseconds=False), end_str=unix_to_datetime_string(end1, in_milliseconds=False))\n",
    "    # print(klines)\n",
    "\n",
    "# Converting data from list to pandas dataframe\n",
    "new_data = pd.DataFrame(data=[row[0:6] for row in klines], columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "data = pd.concat([data, new_data], ignore_index=True)\n",
    "\n",
    "for i in range(periods - 1):\n",
    "    # Moving the start and end interval to next day\n",
    "    start1 = next_30_days_unix_timestamp(start1)\n",
    "    end1 = next_30_days_unix_timestamp(start1)\n",
    "\n",
    "    # downloading candlestick lines\n",
    "    klines = client.get_historical_klines(TICKER, client.KLINE_INTERVAL_1HOUR, limit=LIMIT, start_str=unix_to_datetime_string(start1, in_milliseconds=False), end_str=unix_to_datetime_string(end1, in_milliseconds=False))\n",
    "    # print(klines)\n",
    "\n",
    "    # Converting data from list to pandas dataframe\n",
    "    new_data = pd.DataFrame(data=[row[0:6] for row in klines], columns=[\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # concatinating the new data with the existing data\n",
    "    data = pd.concat([data, new_data], ignore_index=True)\n",
    "\n",
    "# converting all time values from unix to readable string, not important, just for visual purposes and fact checking\n",
    "data[\"time\"] = data[\"time\"].apply(unix_to_datetime_string) #converting time from \n",
    "\n",
    "raw_data = data\n",
    "display(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAUSDT:time</th>\n",
       "      <th>ADAUSDT:high</th>\n",
       "      <th>ADAUSDT:low</th>\n",
       "      <th>ADAUSDT:close</th>\n",
       "      <th>ADAUSDT:volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-17 05:00:00</td>\n",
       "      <td>4.268567</td>\n",
       "      <td>-2.438110</td>\n",
       "      <td>-1.725431</td>\n",
       "      <td>2.139452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-17 06:00:00</td>\n",
       "      <td>0.667404</td>\n",
       "      <td>-5.419320</td>\n",
       "      <td>-2.124252</td>\n",
       "      <td>1.228333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-17 07:00:00</td>\n",
       "      <td>2.486166</td>\n",
       "      <td>-0.674149</td>\n",
       "      <td>0.140285</td>\n",
       "      <td>-44.346902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-17 08:00:00</td>\n",
       "      <td>1.412077</td>\n",
       "      <td>-1.587611</td>\n",
       "      <td>-0.019504</td>\n",
       "      <td>-25.095919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17 09:00:00</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>-1.291405</td>\n",
       "      <td>-0.370645</td>\n",
       "      <td>-23.658621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61337</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>-0.223571</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>12.376273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61338</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>0.255224</td>\n",
       "      <td>-0.255224</td>\n",
       "      <td>0.079758</td>\n",
       "      <td>-49.874502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61339</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>0.223179</td>\n",
       "      <td>-0.271003</td>\n",
       "      <td>0.127531</td>\n",
       "      <td>32.933255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61340</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>0.589078</td>\n",
       "      <td>-0.302500</td>\n",
       "      <td>0.461710</td>\n",
       "      <td>151.535496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61341</th>\n",
       "      <td>2025-04-18 22:00:00</td>\n",
       "      <td>0.142608</td>\n",
       "      <td>-0.602123</td>\n",
       "      <td>-0.554587</td>\n",
       "      <td>-32.184869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61342 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ADAUSDT:time  ADAUSDT:high  ADAUSDT:low  ADAUSDT:close  \\\n",
       "0      2018-04-17 05:00:00      4.268567    -2.438110      -1.725431   \n",
       "1      2018-04-17 06:00:00      0.667404    -5.419320      -2.124252   \n",
       "2      2018-04-17 07:00:00      2.486166    -0.674149       0.140285   \n",
       "3      2018-04-17 08:00:00      1.412077    -1.587611      -0.019504   \n",
       "4      2018-04-17 09:00:00      1.361632    -1.291405      -0.370645   \n",
       "...                    ...           ...          ...            ...   \n",
       "61337  2025-04-18 18:00:00      0.479080    -0.223571       0.127755   \n",
       "61338  2025-04-18 19:00:00      0.255224    -0.255224       0.079758   \n",
       "61339  2025-04-18 20:00:00      0.223179    -0.271003       0.127531   \n",
       "61340  2025-04-18 21:00:00      0.589078    -0.302500       0.461710   \n",
       "61341  2025-04-18 22:00:00      0.142608    -0.602123      -0.554587   \n",
       "\n",
       "       ADAUSDT:volume  \n",
       "0            2.139452  \n",
       "1            1.228333  \n",
       "2          -44.346902  \n",
       "3          -25.095919  \n",
       "4          -23.658621  \n",
       "...               ...  \n",
       "61337       12.376273  \n",
       "61338      -49.874502  \n",
       "61339       32.933255  \n",
       "61340      151.535496  \n",
       "61341      -32.184869  \n",
       "\n",
       "[61342 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################## PREPROCESSING DATA ####################################################################\n",
    "\n",
    "# New dataobject for storing processed data\n",
    "# processed_data = {f\"{TICKER}:time\": [], f\"{TICKER}:open\": [], f\"{TICKER}:high\": [], f\"{TICKER}:low\": [], f\"{TICKER}:close\": [], f\"{TICKER}:volume\": []}\n",
    "processed_data = {f\"{TICKER}:time\": [], f\"{TICKER}:high\": [], f\"{TICKER}:low\": [], f\"{TICKER}:close\": [], f\"{TICKER}:volume\": []}\n",
    "\n",
    "for i, o in enumerate(raw_data[\"open\"]): #o == open, the open price value of the candle stick\n",
    "    if i == 0: #Skipping the first hour to calculate the percent diff using this hour\n",
    "        continue\n",
    "\n",
    "    if o == 0:\n",
    "        continue\n",
    "\n",
    "    processed_data[f\"{TICKER}:time\"].append(raw_data[\"time\"][i]) #time is the same\n",
    "    # processed_data[f\"{TICKER}:open\"].append(percent_difference(float(data[\"open\"][i-1]), float(o))) # percent difference between the opening price of the prior candlestick vs. open of current candle\n",
    "    processed_data[f\"{TICKER}:high\"].append(percent_difference(float(o), float(raw_data[\"high\"][i]))) # percent diff between open and high\n",
    "    processed_data[f\"{TICKER}:low\"].append(percent_difference(float(o), float(raw_data[\"low\"][i]))) # percent diff between open and low\n",
    "    processed_data[f\"{TICKER}:close\"].append(percent_difference(float(o), float(raw_data[\"close\"][i]))) # percent diff between open and close\n",
    "    processed_data[f\"{TICKER}:volume\"].append(percent_difference(float(raw_data[\"volume\"][i-1]), float(raw_data[\"volume\"][i]))) # percent difference between the colume of the prior candlestick vs. open of current candle\n",
    "\n",
    "\n",
    "# processed_data = pd.DataFrame(data=processed_data, columns=[f\"{TICKER}:time\", f\"{TICKER}:open\", f\"{TICKER}:high\", f\"{TICKER}:low\", f\"{TICKER}:close\", f\"{TICKER}:volume\"])\n",
    "processed_data = pd.DataFrame(data=processed_data, columns=[f\"{TICKER}:time\", f\"{TICKER}:high\", f\"{TICKER}:low\", f\"{TICKER}:close\", f\"{TICKER}:volume\"])\n",
    "display(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DATAPOINTS: 51342\n",
      "MEAN CLOSE: 0.006801309768745919\n",
      "MEDIAN CLOSE: 0.0\n",
      "MAX CLOSE IN DATASET: 15.037173235270618\n",
      "OCCURRENCES OVER 0.0: 25119 - PERCENT OF DATASET: 49.0%\n",
      "OCCURRENCES OVER 0.1: 22509 - PERCENT OF DATASET: 44.0%\n",
      "OCCURRENCES OVER 0.2: 19542 - PERCENT OF DATASET: 38.0%\n",
      "OCCURRENCES OVER 0.3: 16858 - PERCENT OF DATASET: 33.0%\n",
      "OCCURRENCES OVER 0.4: 14407 - PERCENT OF DATASET: 28.000000000000004%\n",
      "OCCURRENCES OVER 0.5: 12369 - PERCENT OF DATASET: 24.0%\n",
      "----------------------------------------------------------------------\n",
      "EVALUATION DATA\n",
      "TOTAL DATAPOINTS: 10000\n",
      "MEAN CLOSE: 0.006578835555302232\n",
      "MEDIAN CLOSE: 0.0\n",
      "MAX CLOSE IN DATASET: 33.70907967881409\n",
      "OCCURRENCES OVER 0.0: 4889 - PERCENT OF DATASET: 49.0%\n",
      "OCCURRENCES OVER 0.1: 4324 - PERCENT OF DATASET: 43.0%\n",
      "OCCURRENCES OVER 0.2: 3791 - PERCENT OF DATASET: 38.0%\n",
      "OCCURRENCES OVER 0.3: 3265 - PERCENT OF DATASET: 33.0%\n",
      "OCCURRENCES OVER 0.4: 2789 - PERCENT OF DATASET: 28.000000000000004%\n",
      "OCCURRENCES OVER 0.5: 2383 - PERCENT OF DATASET: 24.0%\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "############################# STATISTICAL ANALYSIS OF PROCESSED DATA #######################################\n",
    "import statistics as st\n",
    "\n",
    "close_data_processed = processed_data[f\"{TICKER}:close\"].to_list()\n",
    "close_data_processed = close_data_processed[:-10000]\n",
    "print(f\"TOTAL DATAPOINTS: {len(close_data_processed)}\")\n",
    "print(f\"MEAN CLOSE: {st.mean(close_data_processed)}\")\n",
    "print(f\"MEDIAN CLOSE: {st.median(close_data_processed)}\")\n",
    "\n",
    "print(f\"MAX CLOSE IN DATASET: {max(close_data_processed)}\")\n",
    "print(f\"OCCURRENCES OVER 0.0: {sum(x > 0 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.1: {sum(x > 0.1 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.1 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.2: {sum(x > 0.2 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.2 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.3: {sum(x > 0.3 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.3 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.4: {sum(x > 0.4 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.4 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.5: {sum(x > 0.5 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.5 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "print(\"EVALUATION DATA\")\n",
    "close_data_processed = processed_data[f\"{TICKER}:close\"].to_list()\n",
    "close_data_processed = close_data_processed[-10000:]\n",
    "print(f\"TOTAL DATAPOINTS: {len(close_data_processed)}\")\n",
    "print(f\"MEAN CLOSE: {st.mean(close_data_processed)}\")\n",
    "print(f\"MEDIAN CLOSE: {st.median(close_data_processed)}\")\n",
    "\n",
    "print(f\"MAX CLOSE IN DATASET: {max(close_data_processed)}\")\n",
    "print(f\"OCCURRENCES OVER 0.0: {sum(x > 0 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.1: {sum(x > 0.1 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.1 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.2: {sum(x > 0.2 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.2 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.3: {sum(x > 0.3 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.3 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.4: {sum(x > 0.4 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.4 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(f\"OCCURRENCES OVER 0.5: {sum(x > 0.5 for x in close_data_processed)} - PERCENT OF DATASET: {round(sum(x > 0.5 for x in close_data_processed) / len(close_data_processed), 2) * 100}%\")\n",
    "print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ADAUSDT:high0</th>\n",
       "      <th>ADAUSDT:low0</th>\n",
       "      <th>ADAUSDT:close0</th>\n",
       "      <th>ADAUSDT:volume0</th>\n",
       "      <th>ADAUSDT:high1</th>\n",
       "      <th>ADAUSDT:low1</th>\n",
       "      <th>ADAUSDT:close1</th>\n",
       "      <th>ADAUSDT:volume1</th>\n",
       "      <th>ADAUSDT:high2</th>\n",
       "      <th>...</th>\n",
       "      <th>ADAUSDT:volume2</th>\n",
       "      <th>ADAUSDT:high3</th>\n",
       "      <th>ADAUSDT:low3</th>\n",
       "      <th>ADAUSDT:close3</th>\n",
       "      <th>ADAUSDT:volume3</th>\n",
       "      <th>ADAUSDT:high4</th>\n",
       "      <th>ADAUSDT:low4</th>\n",
       "      <th>ADAUSDT:close4</th>\n",
       "      <th>ADAUSDT:volume4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-17 09:00:00</td>\n",
       "      <td>4.268567</td>\n",
       "      <td>-2.438110</td>\n",
       "      <td>-1.725431</td>\n",
       "      <td>2.139452</td>\n",
       "      <td>0.667404</td>\n",
       "      <td>-5.419320</td>\n",
       "      <td>-2.124252</td>\n",
       "      <td>1.228333</td>\n",
       "      <td>2.486166</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.346902</td>\n",
       "      <td>1.412077</td>\n",
       "      <td>-1.587611</td>\n",
       "      <td>-0.019504</td>\n",
       "      <td>-25.095919</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>-1.291405</td>\n",
       "      <td>-0.370645</td>\n",
       "      <td>-23.658621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-17 10:00:00</td>\n",
       "      <td>0.667404</td>\n",
       "      <td>-5.419320</td>\n",
       "      <td>-2.124252</td>\n",
       "      <td>1.228333</td>\n",
       "      <td>2.486166</td>\n",
       "      <td>-0.674149</td>\n",
       "      <td>0.140285</td>\n",
       "      <td>-44.346902</td>\n",
       "      <td>1.412077</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.095919</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>-1.291405</td>\n",
       "      <td>-0.370645</td>\n",
       "      <td>-23.658621</td>\n",
       "      <td>0.288780</td>\n",
       "      <td>-1.190244</td>\n",
       "      <td>0.050732</td>\n",
       "      <td>-20.581889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-17 11:00:00</td>\n",
       "      <td>2.486166</td>\n",
       "      <td>-0.674149</td>\n",
       "      <td>0.140285</td>\n",
       "      <td>-44.346902</td>\n",
       "      <td>1.412077</td>\n",
       "      <td>-1.587611</td>\n",
       "      <td>-0.019504</td>\n",
       "      <td>-25.095919</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.658621</td>\n",
       "      <td>0.288780</td>\n",
       "      <td>-1.190244</td>\n",
       "      <td>0.050732</td>\n",
       "      <td>-20.581889</td>\n",
       "      <td>2.192059</td>\n",
       "      <td>-0.538264</td>\n",
       "      <td>1.915126</td>\n",
       "      <td>-6.651501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-17 12:00:00</td>\n",
       "      <td>1.412077</td>\n",
       "      <td>-1.587611</td>\n",
       "      <td>-0.019504</td>\n",
       "      <td>-25.095919</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>-1.291405</td>\n",
       "      <td>-0.370645</td>\n",
       "      <td>-23.658621</td>\n",
       "      <td>0.288780</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.581889</td>\n",
       "      <td>2.192059</td>\n",
       "      <td>-0.538264</td>\n",
       "      <td>1.915126</td>\n",
       "      <td>-6.651501</td>\n",
       "      <td>2.157336</td>\n",
       "      <td>-1.919761</td>\n",
       "      <td>-1.218531</td>\n",
       "      <td>95.086660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17 13:00:00</td>\n",
       "      <td>1.361632</td>\n",
       "      <td>-1.291405</td>\n",
       "      <td>-0.370645</td>\n",
       "      <td>-23.658621</td>\n",
       "      <td>0.288780</td>\n",
       "      <td>-1.190244</td>\n",
       "      <td>0.050732</td>\n",
       "      <td>-20.581889</td>\n",
       "      <td>2.192059</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.651501</td>\n",
       "      <td>2.157336</td>\n",
       "      <td>-1.919761</td>\n",
       "      <td>-1.218531</td>\n",
       "      <td>95.086660</td>\n",
       "      <td>0.849529</td>\n",
       "      <td>-0.306451</td>\n",
       "      <td>-0.108616</td>\n",
       "      <td>-51.258434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61332</th>\n",
       "      <td>2025-04-18 17:00:00</td>\n",
       "      <td>0.226868</td>\n",
       "      <td>-0.340301</td>\n",
       "      <td>0.145843</td>\n",
       "      <td>-26.006756</td>\n",
       "      <td>0.420780</td>\n",
       "      <td>-0.388412</td>\n",
       "      <td>-0.097103</td>\n",
       "      <td>79.098599</td>\n",
       "      <td>0.113397</td>\n",
       "      <td>...</td>\n",
       "      <td>47.491798</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-0.097371</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-20.884357</td>\n",
       "      <td>1.080819</td>\n",
       "      <td>-0.032263</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>37.673761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61333</th>\n",
       "      <td>2025-04-18 18:00:00</td>\n",
       "      <td>0.420780</td>\n",
       "      <td>-0.388412</td>\n",
       "      <td>-0.097103</td>\n",
       "      <td>79.098599</td>\n",
       "      <td>0.113397</td>\n",
       "      <td>-0.631784</td>\n",
       "      <td>-0.178195</td>\n",
       "      <td>47.491798</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.884357</td>\n",
       "      <td>1.080819</td>\n",
       "      <td>-0.032263</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>37.673761</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>-0.223571</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>12.376273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61334</th>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>0.113397</td>\n",
       "      <td>-0.631784</td>\n",
       "      <td>-0.178195</td>\n",
       "      <td>47.491798</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-0.097371</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-20.884357</td>\n",
       "      <td>1.080819</td>\n",
       "      <td>...</td>\n",
       "      <td>37.673761</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>-0.223571</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>12.376273</td>\n",
       "      <td>0.255224</td>\n",
       "      <td>-0.255224</td>\n",
       "      <td>0.079758</td>\n",
       "      <td>-49.874502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61335</th>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-0.097371</td>\n",
       "      <td>0.600454</td>\n",
       "      <td>-20.884357</td>\n",
       "      <td>1.080819</td>\n",
       "      <td>-0.032263</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>37.673761</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>...</td>\n",
       "      <td>12.376273</td>\n",
       "      <td>0.255224</td>\n",
       "      <td>-0.255224</td>\n",
       "      <td>0.079758</td>\n",
       "      <td>-49.874502</td>\n",
       "      <td>0.223179</td>\n",
       "      <td>-0.271003</td>\n",
       "      <td>0.127531</td>\n",
       "      <td>32.933255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61336</th>\n",
       "      <td>2025-04-18 21:00:00</td>\n",
       "      <td>1.080819</td>\n",
       "      <td>-0.032263</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>37.673761</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>-0.223571</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>12.376273</td>\n",
       "      <td>0.255224</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.874502</td>\n",
       "      <td>0.223179</td>\n",
       "      <td>-0.271003</td>\n",
       "      <td>0.127531</td>\n",
       "      <td>32.933255</td>\n",
       "      <td>0.589078</td>\n",
       "      <td>-0.302500</td>\n",
       "      <td>0.461710</td>\n",
       "      <td>151.535496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61337 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time  ADAUSDT:high0  ADAUSDT:low0  ADAUSDT:close0  \\\n",
       "0      2018-04-17 09:00:00       4.268567     -2.438110       -1.725431   \n",
       "1      2018-04-17 10:00:00       0.667404     -5.419320       -2.124252   \n",
       "2      2018-04-17 11:00:00       2.486166     -0.674149        0.140285   \n",
       "3      2018-04-17 12:00:00       1.412077     -1.587611       -0.019504   \n",
       "4      2018-04-17 13:00:00       1.361632     -1.291405       -0.370645   \n",
       "...                    ...            ...           ...             ...   \n",
       "61332  2025-04-18 17:00:00       0.226868     -0.340301        0.145843   \n",
       "61333  2025-04-18 18:00:00       0.420780     -0.388412       -0.097103   \n",
       "61334  2025-04-18 19:00:00       0.113397     -0.631784       -0.178195   \n",
       "61335  2025-04-18 20:00:00       0.600454     -0.097371        0.600454   \n",
       "61336  2025-04-18 21:00:00       1.080819     -0.032263        1.000161   \n",
       "\n",
       "       ADAUSDT:volume0  ADAUSDT:high1  ADAUSDT:low1  ADAUSDT:close1  \\\n",
       "0             2.139452       0.667404     -5.419320       -2.124252   \n",
       "1             1.228333       2.486166     -0.674149        0.140285   \n",
       "2           -44.346902       1.412077     -1.587611       -0.019504   \n",
       "3           -25.095919       1.361632     -1.291405       -0.370645   \n",
       "4           -23.658621       0.288780     -1.190244        0.050732   \n",
       "...                ...            ...           ...             ...   \n",
       "61332       -26.006756       0.420780     -0.388412       -0.097103   \n",
       "61333        79.098599       0.113397     -0.631784       -0.178195   \n",
       "61334        47.491798       0.600454     -0.097371        0.600454   \n",
       "61335       -20.884357       1.080819     -0.032263        1.000161   \n",
       "61336        37.673761       0.479080     -0.223571        0.127755   \n",
       "\n",
       "       ADAUSDT:volume1  ADAUSDT:high2  ...  ADAUSDT:volume2  ADAUSDT:high3  \\\n",
       "0             1.228333       2.486166  ...       -44.346902       1.412077   \n",
       "1           -44.346902       1.412077  ...       -25.095919       1.361632   \n",
       "2           -25.095919       1.361632  ...       -23.658621       0.288780   \n",
       "3           -23.658621       0.288780  ...       -20.581889       2.192059   \n",
       "4           -20.581889       2.192059  ...        -6.651501       2.157336   \n",
       "...                ...            ...  ...              ...            ...   \n",
       "61332        79.098599       0.113397  ...        47.491798       0.600454   \n",
       "61333        47.491798       0.600454  ...       -20.884357       1.080819   \n",
       "61334       -20.884357       1.080819  ...        37.673761       0.479080   \n",
       "61335        37.673761       0.479080  ...        12.376273       0.255224   \n",
       "61336        12.376273       0.255224  ...       -49.874502       0.223179   \n",
       "\n",
       "       ADAUSDT:low3  ADAUSDT:close3  ADAUSDT:volume3  ADAUSDT:high4  \\\n",
       "0         -1.587611       -0.019504       -25.095919       1.361632   \n",
       "1         -1.291405       -0.370645       -23.658621       0.288780   \n",
       "2         -1.190244        0.050732       -20.581889       2.192059   \n",
       "3         -0.538264        1.915126        -6.651501       2.157336   \n",
       "4         -1.919761       -1.218531        95.086660       0.849529   \n",
       "...             ...             ...              ...            ...   \n",
       "61332     -0.097371        0.600454       -20.884357       1.080819   \n",
       "61333     -0.032263        1.000161        37.673761       0.479080   \n",
       "61334     -0.223571        0.127755        12.376273       0.255224   \n",
       "61335     -0.255224        0.079758       -49.874502       0.223179   \n",
       "61336     -0.271003        0.127531        32.933255       0.589078   \n",
       "\n",
       "       ADAUSDT:low4  ADAUSDT:close4  ADAUSDT:volume4  Label  \n",
       "0         -1.291405       -0.370645       -23.658621      0  \n",
       "1         -1.190244        0.050732       -20.581889      1  \n",
       "2         -0.538264        1.915126        -6.651501      0  \n",
       "3         -1.919761       -1.218531        95.086660      0  \n",
       "4         -0.306451       -0.108616       -51.258434      0  \n",
       "...             ...             ...              ...    ...  \n",
       "61332     -0.032263        1.000161        37.673761      1  \n",
       "61333     -0.223571        0.127755        12.376273      0  \n",
       "61334     -0.255224        0.079758       -49.874502      1  \n",
       "61335     -0.271003        0.127531        32.933255      1  \n",
       "61336     -0.302500        0.461710       151.535496      0  \n",
       "\n",
       "[61337 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### LABELING THE DATA ##################################\n",
    "\n",
    "\n",
    "# column_labels = [\"BTCUSDT:time\"] # name of the columns for the return dataframe\n",
    "column_labels = [\"time\"] # name of the columns for the return dataframe\n",
    "\n",
    "# filling up the list with labels for the columns\n",
    "for roundd in range(EPOCHS):\n",
    "    for option in options:\n",
    "        column_labels.append(f\"{TICKER}:{option}{roundd}\")\n",
    "\n",
    "column_labels.append(\"Label\")\n",
    "\n",
    "\n",
    "# filling up list of data, row by row in the dataset\n",
    "labelled_data_rows = [] # this list stores all the rows filled with all the data\n",
    "for i in range(len(processed_data[TIME]) - EPOCHS): #looping from the third element to the third last element, with stepsize 1, if epoch=3\n",
    "    data_row = []\n",
    "\n",
    "    data_row.append(processed_data[TIME][i + EPOCHS - 1])\n",
    "\n",
    "    for t in range(EPOCHS):\n",
    "        for option in options:\n",
    "            data_row.append(processed_data[f\"{TICKER}:{option}\"][i + t])\n",
    "\n",
    "    if processed_data[PREDICTOR][i + EPOCHS] >= THRESHOLD: # here we use the threshold, AND APPEND THE LABEL\n",
    "        data_row.append(1)\n",
    "    else:\n",
    "        data_row.append(0)\n",
    "\n",
    "    labelled_data_rows.append(data_row)\n",
    "\n",
    "\n",
    "labelled_data_frame = pd.DataFrame(labelled_data_rows, columns=column_labels)\n",
    "display(labelled_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This code block divides the dataset into a training dataset and trains a new model using the **AutoGluon Tabular** predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\47981\\Desktop\\MasterThesis\\Repo\\MasterThesis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250603_104644\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       3.23 GB / 15.92 GB (20.3%)\n",
      "Disk Space Avail:   113.35 GB / 475.69 GB (23.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20250603_104644\"\n",
      "Train Data Rows:    51337\n",
      "Train Data Columns: 20\n",
      "Label Column:       Label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3298.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.83 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['ADAUSDT:high0', 'ADAUSDT:low0', 'ADAUSDT:close0', 'ADAUSDT:volume0', 'ADAUSDT:high1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['ADAUSDT:high0', 'ADAUSDT:low0', 'ADAUSDT:close0', 'ADAUSDT:volume0', 'ADAUSDT:high1', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.83 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.04869782028556402, Train Rows: 48837, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5256\t = Validation score   (accuracy)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5248\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.578\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.5792\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5656\t = Validation score   (accuracy)\n",
      "\t11.93s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5676\t = Validation score   (accuracy)\n",
      "\t19.28s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.5796\t = Validation score   (accuracy)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 219 due to low memory. Expected memory usage reduced from 20.53% -> 15.0% of available memory...\n",
      "\t0.5596\t = Validation score   (accuracy)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 218 due to low memory. Expected memory usage reduced from 20.57% -> 15.0% of available memory...\n",
      "\t0.568\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.5824\t = Validation score   (accuracy)\n",
      "\t57.61s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.5808\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.576\t = Validation score   (accuracy)\n",
      "\t76.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.5772\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.684, 'ExtraTreesEntr': 0.158, 'LightGBMXT': 0.053, 'XGBoost': 0.053, 'NeuralNetTorch': 0.053}\n",
      "\t0.584\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.92s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 19630.6 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20250603_104644\")\n"
     ]
    }
   ],
   "source": [
    "################################ TRAINING NEW MODEL #######################################\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# defining training size and colums to use for training within the labelled dataset\n",
    "VALIDATION_SIZE = 10000\n",
    "columns_to_use = [f\"{TICKER}:high0\", f\"{TICKER}:low0\", f\"{TICKER}:close0\", f\"{TICKER}:volume0\", f\"{TICKER}:high1\", f\"{TICKER}:low1\", f\"{TICKER}:close1\", f\"{TICKER}:volume1\", f\"{TICKER}:high2\", f\"{TICKER}:low2\", f\"{TICKER}:close2\", f\"{TICKER}:volume2\", f\"{TICKER}:high3\", f\"{TICKER}:low3\", f\"{TICKER}:close3\", f\"{TICKER}:volume3\", f\"{TICKER}:high4\", f\"{TICKER}:low4\", f\"{TICKER}:close4\", f\"{TICKER}:volume4\", \"Label\"]\n",
    "LABEL = \"Label\"\n",
    "\n",
    "# defining training data\n",
    "training_dataframe = labelled_data_frame.iloc[:-VALIDATION_SIZE].copy()\n",
    "train_data_frame2 = training_dataframe[columns_to_use]\n",
    "train_tabular_dataset = TabularDataset(train_data_frame2)\n",
    "\n",
    "# # Training model -> TabularPredictor\n",
    "# predictor = TabularPredictor(label=label, eval_metric=\"balanced_accuracy\", positive_class=1).fit(train_tabular_dataset, num_bag_folds=5, num_bag_sets=5, num_stack_levels=3)\n",
    "# predictor = TabularPredictor(label=label, eval_metric=\"accuracy\").fit(train_tabular_dataset, presets=\"high_quality\")\n",
    "predictor = TabularPredictor(label=LABEL).fit(train_tabular_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This code block divides the dataset into a validation dataset and evaluates the model using the **AutoGluons** inbuilt evaluation library. In addition the model is backtested using the validation set to measure its performance and calulate its \"expected return\" over the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51337    0\n",
       "51338    0\n",
       "51339    0\n",
       "51340    0\n",
       "51341    0\n",
       "        ..\n",
       "61332    0\n",
       "61333    0\n",
       "61334    0\n",
       "61335    0\n",
       "61336    0\n",
       "Name: Label, Length: 10000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5683,\n",
       " 'balanced_accuracy': 0.5190982985633719,\n",
       " 'mcc': 0.05563701144249248,\n",
       " 'roc_auc': 0.5497355786312232,\n",
       " 'f1': 0.2371443717971373,\n",
       " 'precision': 0.5026217228464419,\n",
       " 'recall': 0.15518038852913968,\n",
       " 'confusion_matrix':       0    1\n",
       " 0  5012  664\n",
       " 1  3653  671,\n",
       " 'classification_report': {'0': {'precision': 0.5784189267166763,\n",
       "   'recall': 0.883016208597604,\n",
       "   'f1-score': 0.6989749668781814,\n",
       "   'support': 5676.0},\n",
       "  '1': {'precision': 0.5026217228464419,\n",
       "   'recall': 0.15518038852913968,\n",
       "   'f1-score': 0.2371443717971373,\n",
       "   'support': 4324.0},\n",
       "  'accuracy': 0.5683,\n",
       "  'macro avg': {'precision': 0.5405203247815591,\n",
       "   'recall': 0.5190982985633719,\n",
       "   'f1-score': 0.46805966933765936,\n",
       "   'support': 10000.0},\n",
       "  'weighted avg': {'precision': 0.5456442157631869,\n",
       "   'recall': 0.5683,\n",
       "   'f1-score': 0.49927941756513794,\n",
       "   'support': 10000.0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 20 features using 5000 rows with 5 shuffle sets...\n",
      "\t73.61s\t= Expected runtime (14.72s per shuffle set)\n",
      "\t18.51s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:close4</th>\n",
       "      <td>0.02484</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>0.010161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:low2</th>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.204459</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:volume4</th>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.324131</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>-0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:low3</th>\n",
       "      <td>-0.00008</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.536898</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>-0.003816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:close3</th>\n",
       "      <td>-0.00008</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.507283</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>-0.019044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:low1</th>\n",
       "      <td>-0.00016</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.620404</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>-0.002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:volume0</th>\n",
       "      <td>-0.00028</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.701484</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>-0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:volume3</th>\n",
       "      <td>-0.00028</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.596858</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>-0.005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:high2</th>\n",
       "      <td>-0.00060</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.729980</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.004728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:volume2</th>\n",
       "      <td>-0.00060</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.865004</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>-0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:close1</th>\n",
       "      <td>-0.00112</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.897180</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>-0.004536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:close0</th>\n",
       "      <td>-0.00128</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.861677</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>-0.005963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:close2</th>\n",
       "      <td>-0.00132</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.884107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>-0.005635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:high4</th>\n",
       "      <td>-0.00136</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.815634</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>-0.007547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:low0</th>\n",
       "      <td>-0.00148</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.960010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>-0.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:volume1</th>\n",
       "      <td>-0.00148</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.990168</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:high1</th>\n",
       "      <td>-0.00148</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.978685</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>-0.003802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:high0</th>\n",
       "      <td>-0.00184</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001303</td>\n",
       "      <td>-0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:high3</th>\n",
       "      <td>-0.00216</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.889391</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>-0.009029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAUSDT:low4</th>\n",
       "      <td>-0.00280</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.903156</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>-0.011062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance    stddev   p_value  n  p99_high   p99_low\n",
       "ADAUSDT:close4      0.02484  0.007129  0.000732  5  0.039519  0.010161\n",
       "ADAUSDT:low2        0.00052  0.001262  0.204459  5  0.003118 -0.002078\n",
       "ADAUSDT:volume4     0.00024  0.001090  0.324131  5  0.002484 -0.002004\n",
       "ADAUSDT:low3       -0.00008  0.001814  0.536898  5  0.003656 -0.003816\n",
       "ADAUSDT:close3     -0.00008  0.009210  0.507283  5  0.018884 -0.019044\n",
       "ADAUSDT:low1       -0.00016  0.001090  0.620404  5  0.002084 -0.002404\n",
       "ADAUSDT:volume0    -0.00028  0.001092  0.701484  5  0.001968 -0.002528\n",
       "ADAUSDT:volume3    -0.00028  0.002390  0.596858  5  0.004641 -0.005201\n",
       "ADAUSDT:high2      -0.00060  0.002005  0.729980  5  0.003528 -0.004728\n",
       "ADAUSDT:volume2    -0.00060  0.001049  0.865004  5  0.001560 -0.002760\n",
       "ADAUSDT:close1     -0.00112  0.001659  0.897180  5  0.002296 -0.004536\n",
       "ADAUSDT:close0     -0.00128  0.002274  0.861677  5  0.003403 -0.005963\n",
       "ADAUSDT:close2     -0.00132  0.002096  0.884107  5  0.002995 -0.005635\n",
       "ADAUSDT:high4      -0.00136  0.003005  0.815634  5  0.004827 -0.007547\n",
       "ADAUSDT:low0       -0.00148  0.001418  0.960010  5  0.001441 -0.004401\n",
       "ADAUSDT:volume1    -0.00148  0.000879  0.990168  5  0.000329 -0.003289\n",
       "ADAUSDT:high1      -0.00148  0.001128  0.978685  5  0.000842 -0.003802\n",
       "ADAUSDT:high0      -0.00184  0.000261  0.999953  5 -0.001303 -0.002377\n",
       "ADAUSDT:high3      -0.00216  0.003336  0.889391  5  0.004709 -0.009029\n",
       "ADAUSDT:low4       -0.00280  0.004012  0.903156  5  0.005462 -0.011062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################### MODEL EVALUATION ################################\n",
    "\n",
    "# Defining the testing set using the training size and columns to use\n",
    "testing_dataframe = labelled_data_frame.tail(VALIDATION_SIZE).copy()\n",
    "#display(testing_dataframe)\n",
    "test_data_frame2 = testing_dataframe[columns_to_use]\n",
    "test_tabular_dataset = TabularDataset(test_data_frame2)\n",
    "\n",
    "######## Making predictions\n",
    "y_pred = predictor.predict(test_tabular_dataset.drop(columns=[LABEL]))\n",
    "display(y_pred)\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "eval_report = predictor.evaluate(test_tabular_dataset, detailed_report=True)\n",
    "display(eval_report)\n",
    "\n",
    "feature_importance = predictor.feature_importance(test_tabular_dataset)\n",
    "display(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0% of the 20 features have **positive** importance.\n",
      "\n",
      "Ranking by HOUR (most â†’ least important):\n",
      "  1. h4   sum importance = 0.020920\n",
      "  2. h2   sum importance = -0.002000\n",
      "  3. h3   sum importance = -0.002600\n",
      "  4. h1   sum importance = -0.004240\n",
      "  5. h0   sum importance = -0.004880\n",
      "\n",
      "Ranking by METRIC (most â†’ least important):\n",
      "  1. close  sum importance = 0.021040\n",
      "  2. volume sum importance = -0.002400\n",
      "  3. low    sum importance = -0.004000\n",
      "  4. high   sum importance = -0.007440\n",
      "\n",
      "Top 5 individual features:\n",
      "  ADAUSDT:close4            0.024840\n",
      "  ADAUSDT:low4              -0.002800\n",
      "  ADAUSDT:high3             -0.002160\n",
      "  ADAUSDT:high0             -0.001840\n",
      "  ADAUSDT:high1             -0.001480\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "METRIC_RE = re.compile(r\":([a-zA-Z]+?)(\\d+)$\")   # capture metric & hour suffix\n",
    "\n",
    "\n",
    "def analyze_feature_importance(feature_names, importances):\n",
    "    \"\"\"\n",
    "    Print a short report on a modelâ€™s feature-importance vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_names : list[str]\n",
    "        All feature names, e.g. [\"SOLUSDT:high4\", \"SOLUSDT:low2\", ...]\n",
    "    importances : list[float]\n",
    "        Matching importance values, same length/order as `feature_names`\n",
    "    \"\"\"\n",
    "    if len(feature_names) != len(importances):\n",
    "        raise ValueError(\"feature_names and importances must be the same length!\")\n",
    "\n",
    "    # â”€â”€ Build a DataFrame â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df = pd.DataFrame(\n",
    "        {\"feature\": feature_names, \"importance\": importances}\n",
    "    ).assign(\n",
    "        metric=lambda d: d[\"feature\"].str.extract(METRIC_RE)[0].str.lower(),\n",
    "        hour=lambda d: pd.to_numeric(\n",
    "            d[\"feature\"].str.extract(METRIC_RE)[1], errors=\"coerce\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Drop rows we could not parse\n",
    "    df = df.dropna(subset=[\"metric\", \"hour\"]).copy()\n",
    "    df[\"hour\"] = df[\"hour\"].astype(int)\n",
    "\n",
    "    # â”€â”€ 1. % of positive importances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    pct_pos = (df[\"importance\"] > 0).mean() * 100\n",
    "\n",
    "    # â”€â”€ 2. Rank by hour (sum of importances per lag) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    hour_scores = df.groupby(\"hour\")[\"importance\"].sum().sort_values(ascending=False)\n",
    "    hour_ranking = hour_scores.index.tolist()\n",
    "\n",
    "    # â”€â”€ 3. Rank by metric (sum of importances per metric) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    metric_scores = (\n",
    "        df.groupby(\"metric\")[\"importance\"].sum().sort_values(ascending=False)\n",
    "    )\n",
    "    metric_ranking = metric_scores.index.tolist()\n",
    "\n",
    "    # â”€â”€ Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(f\"{pct_pos:.1f}% of the {len(df)} features have **positive** importance.\\n\")\n",
    "\n",
    "    print(\"Ranking by HOUR (most â†’ least important):\")\n",
    "    for i, h in enumerate(hour_ranking, 1):\n",
    "        print(f\"  {i}. h{h:<1}   sum importance = {hour_scores[h]:.6f}\")\n",
    "\n",
    "    print(\"\\nRanking by METRIC (most â†’ least important):\")\n",
    "    for i, m in enumerate(metric_ranking, 1):\n",
    "        print(f\"  {i}. {m:<6} sum importance = {metric_scores[m]:.6f}\")\n",
    "\n",
    "    top_features = (\n",
    "        df.loc[df[\"importance\"].abs().sort_values(ascending=False).index]\n",
    "        .head(5)[[\"feature\", \"importance\"]]\n",
    "    )\n",
    "    print(\"\\nTop 5 individual features:\")\n",
    "    for feat, imp in top_features.itertuples(index=False):\n",
    "        print(f\"  {feat:<25} {imp:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analyze_feature_importance(feature_importance.index.to_list(), feature_importance['importance'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN PROB 1 CLASSIFICATION: 0.42546091130673885\n",
      "MAX PROB 1 CLASSIFICATION: 0.8602320551872253\n",
      "MIN PROB 1 CLASSIFICATION: 0.25118935108184814\n",
      "COUNT OF NUMBERS > 0.5: 1335\n",
      "COUNT OF NUMBERS > 0.55: 508\n",
      "COUNT OF NUMBERS > 0.6: 185\n"
     ]
    }
   ],
   "source": [
    "# ANALYSIS OF PREDICTIONS AND PROBABILITIES\n",
    "\n",
    "import statistics as st\n",
    "\n",
    "# making and processing probabilities from evaluation dataset\n",
    "y_prob = predictor.predict_proba(test_tabular_dataset.drop(columns=[LABEL]))\n",
    "\n",
    "validation_probabilities = pd.DataFrame(y_prob).reset_index(drop=True) # probability for each prediction\n",
    "validation_predictions = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "validation_dataset = pd.DataFrame(test_data_frame2).reset_index(drop=True)\n",
    "#display(validation_probabilities)\n",
    "#display(validation_predictions)\n",
    "#display(validation_dataset)\n",
    "\n",
    "print(f\"MEAN PROB 1 CLASSIFICATION: {st.mean(validation_probabilities[1].to_list())}\")\n",
    "print(f\"MAX PROB 1 CLASSIFICATION: {max(validation_probabilities[1].to_list())}\")\n",
    "print(f\"MIN PROB 1 CLASSIFICATION: {min(validation_probabilities[1].to_list())}\")\n",
    "\n",
    "count_above_07 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.5)\n",
    "print(\"COUNT OF NUMBERS > 0.5:\", count_above_07)\n",
    "\n",
    "count_above_08 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.55)\n",
    "print(\"COUNT OF NUMBERS > 0.55:\", count_above_08)\n",
    "\n",
    "count_above_09 = sum(1 for num in validation_probabilities[1].to_list() if num > 0.6)\n",
    "print(\"COUNT OF NUMBERS > 0.6:\", count_above_09)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.7\n",
    "LEVERAGE = 1\n",
    "GAIN = 0.5  # Interpreted as a percentage (e.g., 0.5% if multiplied by /100)\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "bad_trades = []\n",
    "all_trades = []\n",
    "\n",
    "initial_investment = 100\n",
    "current_investment = initial_investment\n",
    "investment_history = []\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        total_trades += 1\n",
    "        \n",
    "        # Check if the prediction was correct\n",
    "        if validation_predictions[\"Label\"][idx] == validation_dataset[\"Label\"][idx]:\n",
    "            correct_trades += 1\n",
    "            \n",
    "            # Record the \"gain\" in your trade list\n",
    "            all_trades.append(GAIN * LEVERAGE)\n",
    "            \n",
    "            # Update current_investment by a factor of (1 + gain%)\n",
    "            current_investment *= 1 + (GAIN / 100 * LEVERAGE)\n",
    "        \n",
    "        else:\n",
    "            # A \"bad\" (wrong) trade - since this focuses on shorting the true close is multiplied by -1\n",
    "            # Grab the next close price; watch out for index out-of-range in real code\n",
    "            true_close = (validation_dataset[f\"{TICKER}:close4\"][idx + 1])\n",
    "            \n",
    "            # Record the trade details\n",
    "            bad_trades.append(round(true_close * LEVERAGE, 3))\n",
    "            all_trades.append(true_close * LEVERAGE)\n",
    "\n",
    "            # Update current_investment by (1 + some factor of true_close?)\n",
    "            current_investment *= 1 + (true_close / 100 * LEVERAGE)\n",
    "    \n",
    "    else:\n",
    "        all_trades.append(0)\n",
    "\n",
    "    # In all cases, record the current investment amount\n",
    "    investment_history.append(current_investment)\n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "total_return = current_investment - initial_investment\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"CORRECT: {correct_trades}\")\n",
    "print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "print(f\"WIN RATE: {round(win_rate, 2)}%\")\n",
    "print(f\"RETURN: {round(total_return, 2)}\")\n",
    "print(f\"INVESTMENT VALUE: {round(current_investment, 2)}\")\n",
    "print(f\"SHARP RATIO: {calculate_sharpe_ratio(all_trades)}\")\n",
    "sharpe_ratio9999 = calculate_sharpe_ratio(validation_dataset[f\"{TICKER}:close4\"].to_list())\n",
    "print(f\"SHARP RATIO ONLY HOLDING ASSET: {sharpe_ratio9999}\")\n",
    "print(f\"MEAN RETURN BAD TRADES: {st.mean(bad_trades)}\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "# Print information about bad trades\n",
    "for trade in bad_trades:\n",
    "    print(trade)\n",
    "\n",
    "# --- Plot the investment history ---\n",
    "true_closes_list = validation_dataset[f\"{TICKER}:close4\"].to_list()\n",
    "true_close_base = 100\n",
    "true_close_base_list = []\n",
    "\n",
    "for close in true_closes_list:\n",
    "    true_close_base *= 1 + (close / 100)\n",
    "    true_close_base_list.append(true_close_base)\n",
    "\n",
    "\n",
    "# # Create a figure with two subplots next to each other\n",
    "# fig, axes = plt.subplots(ncols=2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "# # Plot investment history\n",
    "# axes[0].plot(investment_history)\n",
    "# axes[0].set_title(\"Investment Value Over Time\")\n",
    "# axes[0].set_xlabel(\"Time (Hours)\")\n",
    "# axes[0].set_ylabel(\"Investment Value\")\n",
    "\n",
    "# # Plot true closes\n",
    "# axes[1].plot(true_close_base_list)\n",
    "# axes[1].set_title(\"True Closes Over Time\")\n",
    "# axes[1].set_xlabel(\"Time (Hours)\")\n",
    "# axes[1].set_ylabel(\"Asset close price fluctuations\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(investment_history, label=\"Investment History\", color='red', linewidth=2.5)\n",
    "plt.plot(true_close_base_list, label=\"True Closes\", color='gray', linewidth=1)\n",
    "plt.xlabel(\"Trade Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Investment Value and True Closes Over Trades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ANALYSIS OF TRADING USING CLOSING PRICE ################################\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.8\n",
    "TRADING_FEE = 0.25\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "wrong_trades = 0\n",
    "\n",
    "all_trades = []\n",
    "good_trades = []\n",
    "bad_trades = []\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        true_close = validation_dataset[f\"{TICKER}:close4\"][idx + 1] - TRADING_FEE\n",
    "        \n",
    "        if true_close >= 0:\n",
    "            correct_trades += 1\n",
    "            good_trades.append(true_close)\n",
    "        else:\n",
    "            bad_trades.append(true_close)\n",
    "\n",
    "\n",
    "\n",
    "        total_trades += 1\n",
    "        all_trades.append(true_close)\n",
    "            \n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"CORRECT: {correct_trades}\")\n",
    "print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "print(f\"WIN RATE: {round(win_rate, 2)}%\")\n",
    "print(\"-\" * 34)\n",
    "\n",
    "print(f\"MEAN GOOD TRADES: {st.mean(good_trades)}\")\n",
    "print(f\"MEAN BAD TRADES: {st.mean(bad_trades)}\")\n",
    "\n",
    "investtt = 100\n",
    "investment_history2 = []\n",
    "for trade in all_trades:\n",
    "    investtt *= 1 + (trade / 100)\n",
    "    investment_history2.append(investtt)\n",
    "    # print(trade)\n",
    "\n",
    "print(f\"RETURN: {round(investtt - 100, 3)} %\")\n",
    "\n",
    "# --- Plot the investment history ---\n",
    "plt.plot(investment_history2)\n",
    "plt.xlabel(\"Trade Index\")\n",
    "plt.ylabel(\"Investment Value\")\n",
    "plt.title(\"Investment Value Over Trades\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ANALYSIS OF TRADING USING CLOSING PRICE ################################\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# --- Constants ---\n",
    "MINIMUM_PROBABILITY = 0.5\n",
    "TRADING_FEE = 0.0\n",
    "LEVERAGE = 1\n",
    "\n",
    "# --- Tracking variables ---\n",
    "correct_trades = 0\n",
    "total_trades = 0\n",
    "wrong_trades = 0\n",
    "\n",
    "all_trades = []\n",
    "good_trades = []\n",
    "bad_trades = []\n",
    "investment_value = 100\n",
    "investment_history = []\n",
    "\n",
    "\n",
    "# Go through probabilities alongside their index\n",
    "for idx, prob in enumerate(validation_probabilities[1].to_list()):\n",
    "    \n",
    "    # Check if the predicted probability meets the threshold\n",
    "    if prob >= MINIMUM_PROBABILITY:\n",
    "        true_close = (validation_dataset[f\"{TICKER}:close4\"][idx + 1] - TRADING_FEE) * LEVERAGE # FEE AND LEVERAGE ADJUSTED FOR\n",
    "        \n",
    "        if true_close >= 0:\n",
    "            correct_trades += 1\n",
    "            good_trades.append(true_close)\n",
    "        else:\n",
    "            bad_trades.append(true_close)\n",
    "\n",
    "\n",
    "\n",
    "        total_trades += 1\n",
    "        all_trades.append(true_close)\n",
    "\n",
    "        investment_value *= 1 + (true_close / 100)\n",
    "        investment_history.append(investment_value)\n",
    "    \n",
    "    else:\n",
    "        investment_history.append(investment_value)\n",
    "        all_trades.append(0)\n",
    "\n",
    "            \n",
    "\n",
    "# --- After the loop, calculate stats ---\n",
    "wrong_trades = total_trades - correct_trades\n",
    "win_rate = (correct_trades / total_trades * 100) if total_trades else 0\n",
    "\n",
    "# --- Print results ---\n",
    "#print(f\"CORRECT: {correct_trades}\")\n",
    "#print(f\"WRONG: {wrong_trades}\")\n",
    "print(f\"NUMBER OF TRADES: {total_trades}\")\n",
    "#print(f\"NUMBER OF TRADES 2: {len(investment_history)}\")\n",
    "print(f\"ACCURACY: {round(win_rate, 2)}%\")\n",
    "print(f\"RETURN: {investment_value - 100} %\")\n",
    "print(f\"SHARPE RATIO: {calculate_sharpe_ratio(all_trades)}\")\n",
    "sharpe_ratio9999 = calculate_sharpe_ratio(validation_dataset[f\"{TICKER}:close4\"].to_list())\n",
    "print(f\"SHARPE RATIO ONLY HOLDING ASSET: {sharpe_ratio9999}\")\n",
    "print(f\"MEAN win: {st.mean(good_trades)}\")\n",
    "print(f\"MEAN loss: {st.mean(bad_trades)}\")\n",
    "#print(f\"INVESTMENT VALUE {investment_value}\")\n",
    "\n",
    "# for trade in all_trades:\n",
    "#     print(trade)\n",
    "\n",
    "# --- Plot the investment history ---\n",
    "true_closes_list = validation_dataset[f\"{TICKER}:close4\"].to_list()\n",
    "true_close_base = 100\n",
    "true_close_base_list = []\n",
    "\n",
    "for close in true_closes_list:\n",
    "    true_close_base *= 1 + (close / 100)\n",
    "    true_close_base_list.append(true_close_base)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(investment_history, label=\"Trading Results\", color='red', linewidth=2.5)\n",
    "plt.plot(true_close_base_list, label=\"True Closes\", color='gray', linewidth=1)\n",
    "plt.xlabel(\"Back-test period (h)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Investment Value and True Closes Over Trades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
